<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>博客 on Miao Yu | 于淼 </title>
    <link>/cn/index.xml</link>
    <description>Recent content in 博客 on Miao Yu | 于淼 </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Feb 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/cn/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>十万阅读量的科普</title>
      <link>/cn/2017/10/01/popularization-of-science/</link>
      <pubDate>Sun, 01 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/10/01/popularization-of-science/</guid>
      <description>&lt;p&gt;前几天有新闻说某高校认为科普文阅读量10万+算成果，我觉得还是有点难度的。我用美国科普杂志来举个例子，《科学美国人》全美发行量不到60万，加上《发现》跟《新科学家》，整体发行量也就是一百多万，美国人口大概是中国人口的1/4，也就是说中国即便科普发达到美国的程度，日常感兴趣的人数大概五百万封顶。按说国内也有科普期刊，但那个发行量惨不忍睹，倒不是说国人不感兴趣，只是感兴趣比较晚，很多人没形成看杂志习惯直面了互联网时代。我估计国内微信公号、果壳、知乎、科学网基本已经让可圈住绝大多数关注科普信息的人了，那么这个人数是多少呢？&lt;/p&gt;
&lt;p&gt;不考虑泛知识化的知乎，果壳跟科学网日活用户用一些站长工具去查加起来大概是一百万，我估计这两个网站至少能占总关注流量的20%，所以目前日常对科普感兴趣的人也就是大几百万级别，跟上面那个发行量的估计差不多。这个覆盖面其实应该跟金融、IT等行业差不多，但远不如养生、娱乐八卦还有新闻。那么百万量级的圈子产生10万阅读量相当于个位数百分点的人都看到了，这个还是很了不得的，这要求内容足够有趣又恰到好处的专业，太难了看不懂，太简单不值得传播。&lt;/p&gt;
&lt;p&gt;用科学网博客来看，其文章周最高点击大概两三万，就算是一天点出来的也都是关于科普的，距离10万+还是有距离。这种量级科普文全国每天能出一篇就很不容易了，而且作者也不可能都是一个高校的老师/学生。而且实话说，很多10万+的文章名义上是科普，实际可能是搞怪或泛娱乐化行文，读者看了并不一定有学到新科学知识的感觉。&lt;/p&gt;
&lt;p&gt;也许10万+的科普本就不易，但我觉得当前科普过多关注了知识与事实，缺少科学思想跟历史沿革的传播与论述，这个可能是更需要普及的。&lt;/p&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;科普的背景&lt;/h2&gt;
&lt;p&gt;高中毕业，不论你学的文还是理，知识传授上一般侧重知识或事实本身，或者说学到的是通识。例如地球是圆的、力学有三大定律、元素周期表是按什么排的…这类知识其实就算老师不教，你看看《十万个为什么》什么的也都能知道。科普主要面向知识背景是高中组的，大多数人不进行科研，就算进行科研其很多科学背景知识也是高中的（因为你大学可能学了某个专业，但另外的学科最理想也是停留在高中阶段）。&lt;/p&gt;
&lt;p&gt;这部分内容基本不用科普，或者说包含在更广泛的知识普及中就好了，需要思考推理的部分不多，主要是了解事实，形成背景概念。这对于本来就关注的人没什么难度，但如果是中小学生科普，重点要关注这部分。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;知识向科普&lt;/h2&gt;
&lt;p&gt;大多数科普文章其实是在做大学教材的通俗版，这类文章普及的是专业知识，例如pm2.5是怎么回事？行星间距离如何测量？端粒长度跟寿命关系…这类文章告诉我们从已知的高中阶段背景知识如何得到专业的背景知识，大都是专业概念普及，这个是社会大多数人科学背景的上限，却是专业职业化要求的下限。目前这个层次的科学知识几乎可以被维基百科覆盖，也就是说你可以用维基百科作为这类科普文的一个主要参考，另一方面就是趣味性了，如果你能加入更多互动跟多媒体，自然比枯燥的维基百科要好很多。如果你本科专业是理工学科，那么此类文章基本不用看，因为拿到学士学位就表明你已经掌握了这部分内容。这部分内容互联网的替代效果比较明显，国内做的也不错。但科学知识是不断更新的，如果过分强调已有观点其实不但不是科普，反而是科黑。例如方舟子的作品就有点过分强调知识的正确性而不考虑科学的发展，他本身其实也远离科研很久了，这个语境下他实际成了已有（甚至是过时）科学知识的卫道士的角色。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;前沿科普&lt;/h2&gt;
&lt;p&gt;这部分的科普是从已知走向未知，目前最容易出问题的就是这一部分，因为在这一阶段是要建立在读者有大学水平知识上的已知，同专业的还好，但很可能读者大多数停留在高中阶段，所以他们会看不懂。&lt;/p&gt;
&lt;p&gt;这部分最常见的就是前沿科技成果报道，其实多数人看了后只会产生“高科技”的一个感知，并不能理解掌握其中的知识。在我看来，如果文章只是这样让人不明觉厉，那跟告诉别人我有个魔法箱可以变戏法但不给看内部结构一样，读者跟作者都浪费了时间。这部分写的人最好本身是理工背景且实际进行过至少两个学科以上的科研，同时写作水平也有要求。目前的尴尬在于做科研的不会写，会写的看不懂，然后大家只能很和谐的点下赞，最好的情况就是记住了结论（但要小心记结论并善于操纵读者情感的人，他们通常擅长用海量最新研究把你忽悠得就差跪拜交钱了）。&lt;/p&gt;
&lt;p&gt;但其实我倒觉得一线科研人员不应该对这个陌生，你写的基金或论文前言的前几段也是这个要求，只不过都多少夹了点私货。一般套路是先讲个故事但不说结局，引出研究背景跟意义，然后新发现在哪些方面进行了突破，然后是各专家的采访意见，然后是综合观点，最后又把故事收个尾展望下美好未来，通常也有高质量的图片、插画甚至视频进行解释。&lt;/p&gt;
&lt;p&gt;科学成果的吸引力从来就不如娱乐明星的花边八卦，如果我一天平均有一个小时看书报杂志，那看了花边就不会看科普，注意力总是被竞争的，而且读这类需要有知识背景才能看懂的文章也比较累。从另一个角度看，科普在这个阶段对大众谈不上普及了，但对社会中有求知欲的人而言却很关键，而这部分人很有可能推动科技进一步发展。就国内看，科研工作人员大概也是几百万这个级别，其实面向他们的前沿科普很有必要。遗憾的是，这大几百万从业人员的市场规模非常有限，对他们科普还不如卖成功学鸡汤来的容易，优质内容不能专业化生产，吸引力就很有限。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;科学思想&lt;/h2&gt;
&lt;p&gt;前沿科普走出“看结论”的现状最需要普及的不是知识，因为知识都是比较前沿的，很可能被后续结果推翻掉。前沿科普更重要的是科学研究的思想，这个其实即便一线科研工作者自己可能都比较迷糊，大部分人是站在前人基础上往前推进，前人的研究结论容易保存，但思想可能早就消散了。&lt;/p&gt;
&lt;p&gt;举个例子，我可以找两组高中毕业生，一组让读《审判达尔文》，另一组读《盲眼钟表匠》，完了以后测试其对进化论的认可度，可以预期两个差异会很大。两本书都是从逻辑推理开始的，但结论恰恰相反，如何解释两种思想的冲突？这时候如果没有科学方法论的背景知识，很容易就陷入盲从。可以说，科学思想的科普需要引入这些矛盾而不是结论来让读者进行独立思考判断，并形成存疑并可通过观察与实验验证某个论断的科学素养。&lt;/p&gt;
&lt;p&gt;科学思想或者说方法论其实比知识本身更重要，科学知识可以证伪，但方法跑偏了结论就不靠谱了。通过科学思想的普及，我们可以反观审视科研的每一步并诚实的认错换取进步。但现在很多科学向文章过分强调的知识本身的不可动摇，这对科学思想传播没有好处，属于钻牛角尖了。至少我们要给讨论留下可能性而不是一个个论断，如果结论都确定了，那我们还有必要讨论吗？&lt;/p&gt;
&lt;p&gt;这里理想的文章应侧重于整合已有知识进行创新得到的新知识，基本上只有经验很丰富的人才能站到一定高度上解说一些原理或技术。开篇是一个主题，然后作者需要把相关知识与方法论进行高度整合最后形成自己的结论与见解，跟学术论文要求也差不多。此时仅仅谈思想谈逻辑就不够了，最好要整合历史，把发展沿革搞清楚。我觉得这类文章一个月甚至几个月能看上一篇就很不错了，消化这种文章也需要很长时间。坦言之这个认识高度出的作品属于简本教科书，内容却是职业或专业教科书才覆盖或根本就覆盖不到的，可以参考卢昌海老师的作品还有刘未鹏的博文。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;科学史&lt;/h2&gt;
&lt;p&gt;当前科普文章的另一问题是过分强调了逻辑主导的故事而忽略了历史发展的真实过程。这就导致很多知识在解释时感觉很生硬，没有上下文，直接从石头里蹦出来了。科普文章趣味性的重要来源是故事，历史沿革是很容易讲故事的，教科书普遍采用学科逻辑框架，所以科学史作为科普对于专业科研人员也是有意义的。这个的代表可参考普利策奖非虚构类的获奖名单，很多时候回顾科学史会发现很多有意思的小故事，比明星八卦要精彩多了。&lt;/p&gt;
&lt;p&gt;终极科普可能会走向科幻了，你可以体会其中思考的乐趣，当然知识背景设定就不要管了。自己构建一个逻辑自洽的物理甚至社会运行体制跟历史是非常有挑战性的，但我们终将走向未来。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;新的指标&lt;/h2&gt;
&lt;p&gt;十万阅读量的科普天生是需要知识跟趣味来获取读者的，但更重要的可能是科学思想跟历史的传播，这可以凸显出科学最与众不同的特点，例如不断犯错、重视事实证据、当前存在的不足等等。切不可孤芳自赏，用别人看不懂来作为高深，有些科学知识本身确实不适合普及，但过分用技术名词来包装，然后用泛娱乐的方法来调侃就很没必要了。&lt;/p&gt;
&lt;p&gt;普及类文章的难处在于一方面要影响更多人，另一方面却要保障质量。十万阅读量并不是好指标，含有专业信息网文超过一万阅读其实就很优秀了。让我说另一个需要考虑的指标是评论质量，高质量的评论不仅说明正文很好，也说明可以吸引到高水平的读者，此外评论本身也是科学思想的交锋，读者从这个过程可以学到更多。大家可以去围观下海外期刊或预印本文章下面的评论，哪怕匿名也能体会出读者本身的专业性，反观国内基本上还是情绪化的占多。读者跟作者间从来都是双向选择，越是情绪化，理性读者的流失就越多。&lt;/p&gt;
&lt;p&gt;这是一个竞争注意力的时代，科学知识与方法论有必要在更多人的心中占有一席之地。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>幻化残生中的研究生</title>
      <link>/cn/2017/09/24/ecmb/</link>
      <pubDate>Sun, 24 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/09/24/ecmb/</guid>
      <description>&lt;p&gt;幻化残生，也就是环境、化学、材料跟生物这四大学科的近似谐音，属于各类研究生中实验比例最高的专业。然而，其生存现状并不乐观：&lt;/p&gt;
&lt;p&gt;首先，这四个学科属于建立在脑力劳动之上的体力劳动。例如前处理、过柱、表征、养细胞、涂板子、野外采样等等，流程性非常强，到时间点上不论节假日还是凌晨饭点都得待命，但有时又会发现找个本科生带上两天也能做出来。一个尴尬的事实是实验学科一个重要研究方向就是取代人工操作实现流程自动化与便携化，当实验简单到轻轻一按时，研究生训练得到的技能瞬间贬值，更尴尬的是实现这个过程需要的背景知识是物理、机械跟电子工程而不是幻化残生，会某项实验技能短期可以取得不错的成果，但长期看几乎一定会过时。&lt;/p&gt;
&lt;p&gt;其次，特别拼先进仪器技术，进而导致平台建设重于人才培养。今年这个技术能发顶刊，明年就可能被取代了，有些特殊资源例如光源没有背景想约个机时难得要命，如果不进行一些高开支实验可能编辑就直接拒稿，而先进仪器装备的价格奇高，所以从经济角度，这四个学科都属于很烧钱的。那么这里的尴尬就是你的才能受限于仪器平台，从研究机构角度看，投资仪器显然比投资人才培养在初期更有效果，而人才培养初期其实也就是仪器操作。这个没啥办法，现在很多科学问题的回答其实早就脱离了理论导向阶段，而是我有一个问题想回答，但目前技术回答不了，也就是假设早就有了，就等着新技术检验。你去看这些年诺奖，很多是技术获奖而不是理论获奖。也就是说，实验学科比起人才更需要仪器平台资源。&lt;/p&gt;
&lt;p&gt;再次，这几个学科产业转化基本停留在前言里，毕业后除了年龄比同专业本科生大了不少，在满足业界要求上本质区别并不大，这进一步导致本应分流到业界服务社会的博士硕士继续留在学术界造纸，而想从学术界熬出头你看前人经验借鉴意义不大，很多人没考虑时代造就的红利窗口期而大谈特谈自己的奋斗，但要知道此一时彼一时，目前学术界的门槛比10年前高了很多，同样的奋斗强度10年前进高校很容易，现在可能博后都没人要。如果本科转行也就算了，但到了博士转行就真的是在奉献青春了，当然这可能是无法避免的。&lt;/p&gt;
&lt;p&gt;这些现状经常搞得研究生自身怀疑人生，看着转行金融、咨询、IT的同学心有不甘，用学术理想充值的生活把自己隔离在实验室内，但走出实验室的柴米油盐变量太多，控制不来。同时，你又会很惊奇地发现，这些年报道的学术界年轻有为的青千、优青与各路人生赢家基本都是这四个学科的；而且从经费分配跟论文影响力上看，这四个学科也是超级大户；再从经济学角度去看，你会发现围绕这四个学科的仪器、耗材甚至样品测定跟论文润色服务都已经形成了成熟产业链，行业利润十分惊人。注意，这些产业是对科研进行支撑的而不是业界，如果只是这些行业高速发展而产业界没有起色，那事实上是在用纳税人的经费吹肥皂泡，不会长久。&lt;/p&gt;
&lt;p&gt;这并不奇怪，实验学科的知识与技术更迭速度是非常快的，从走进实验室那一刻，你就会发现师兄师姐用的技术学校里根本就没教过或仅仅做了个展望，系统的学习基本上都被传帮带模式替换。如果你自己不去问为什么，大概率你师兄走的弯路你还得走一遍，你师姐画不出的图你也画不出来。更尴尬的是，有时候你会发现，如果你的想法是属于排列组合出来的，那么其实仪器公司完全可以替你做，他们不做并不是不会，而是等着收服务费，你发你的纸，我赚我的钱，各取所需。在这个场景下如果还没意识到自己的民工本质，那大概率是要做一辈子民工的。&lt;/p&gt;
&lt;p&gt;曾经有人提过学术界存在生态位，大家各做各的相安无事，但这个想法现在看比较天真，因为现在竞争者基本都不是来自学科内，而是其他学科的入侵，如果这个问题你自己学科的人搞不定，别的学科就会过来。例如发现一种新材料，如果你觉得意义不大不掺合短期没啥问题，但做材料的表征完了得找应用出口啊，环境、生物、化学都有，你是无法限制某种研究只关注自己学科问题的，技术有自己的生命力，总有人会转过去，事实上这可能是目前科学进步的一个范式：个别学科突破，带动其他学科发展。&lt;/p&gt;
&lt;p&gt;基础学科对新技术的接受度要快于应用学科，一个常见的模式就是某个数学模型首先应用在物理，然后化学，然后生物，然后是边缘综合学科例如环境、医学，然后就是社会科学。当然也存在某些从应用角度出发的模型后来被应用到其他领域，金融与生命科学中经常出现这样的案例。但你应该发现一个问题，要想解决现在的问题，通常老路是不通的，要么回归基础学科，要么从别的学科借鉴，不论哪一种都需要你持续学习新知识，特别是外学科知识。有一个最简单的办法就是你去看看那些最聪明的人在用什么，然后想想能不能用到自己的学科框架里。&lt;/p&gt;
&lt;p&gt;实验学科的发展有时候是很残酷的，初期势必牺牲掉一批掌握过时技术的研究生，这个国内外都很常见，但国外业界会吸收一部分，国内则是学术界大面积收留，这个问题的后果就是现在很多教授对于学生无力指导，看到概念就回来让研究生试，研究生自然苦不堪言，毕业后就业方向非常窄。但同样是实验学科，高能物理、生物统计的毕业生转行就相对容易些，因为可以去做码农，至少生活水平对得上学位。而很多实验学科的研究生对此并不感兴趣，甚至完全不懂，思想上停留在努力实验发论文拿教职的简单规划上，不喜欢接触社会就只接触仪器。这其实是最大的偷懒，科研是需要脑力持续投入的，如果是实验学科还要加上体力。不但要持续学习，还必须要主动学习，关心前沿，而这又是研究生的普遍弱点。&lt;/p&gt;
&lt;p&gt;学科前沿是一个很模糊的东西，对幻化残生而言，教科书上的实验技术是一定落后于科研的，此时对学术前沿的感知要么来自文献，要么来自会议或培训，坦白说，这两个方法都具有很强的主观性，夹杂很多人的小算盘。好比你想在微信里打开淘宝链接，不是不行，就是要通过复制过程恶心你一把，但其实这种经验过程你也没啥办法。另一个方法是各种文献信息学指标，例如H指数，被引率等等，但这些指标属于后验指标，你得至少等文章发表过去两三年才能开始评价，但这两三年中也会有一大把新趋势出现。还有个方法就是自己当期刊编辑或审稿人，其实这个是很多教授的独门秘笈，因为你会比其他人早好几个月知道新研究的动向，但研究生拿到的审稿机会本来就少，高水平期刊更是不会找研究生审稿。所以其实对于很多研究生而言，想了解前沿跟他人的研究动向几乎不可能，而根据我的观察，如果同行坐到一起聊天你对新动向一无所知，那么对方也就不会在你身上浪费时间了。有些出版方跟研究机构也会发布一些热点文章，但多数基于编辑经验，并不一定准确。&lt;/p&gt;
&lt;p&gt;我之前曾写过用文本分析来探索前沿，但我估计很多人也就是看个热闹，并不真的会用。也罢，这个坑我挖的我填，我做了一个在线app来探索最近三年学科趋势：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://yufreecas.shinyapps.io/journaltone/&#34; class=&#34;uri&#34;&gt;https://yufreecas.shinyapps.io/journaltone/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;之所以选三年，是因为我感觉三年以上用引用指标更靠谱。这个应用保留了最大的自由度，你可以简单修改期刊或关键词用默认代码绘制相关趋势，或者直接尝试修改成看五年甚至十年的趋势。但我需要声明的是这个app我放到一个免费在线平台上，每个月流量有限，超了就没法用了，所以我建议你本地安装运行。源码&lt;a href=&#34;https://github.com/yufree/journaltone&#34;&gt;在此&lt;/a&gt;，此外，本地运行时多数包cran上有，但有一个方便抓pubmed数据的包是我自己写的，你需要从github上下载安装：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;#39;yufree/scifetch&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其实，对于幻化残生的研究生而言，主动了解科研趋势只是一方面，了解你自己才是更重要的。当你觉得不好时，不要总是怪罪时代跟环境，也想想自己身上的问题；当你一帆风顺时，不要总觉得这是自己勤奋与努力的结晶而忘记了科研浪潮的背后推手。随波逐流不会过的太差，但放弃思考是绝难在学术界生存下来的，不要真的幻化残生了。&lt;/p&gt;
&lt;p&gt;师兄只能帮你到这了，剩下的，我也没想明白。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>主成分分析那些事儿</title>
      <link>/cn/2017/09/14/pca/</link>
      <pubDate>Thu, 14 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/09/14/pca/</guid>
      <description>&lt;p&gt;目之所及，主成分分析应该是科研领域里最通用的一种数据分析手段。在相当长的一段时间里，我认为这种方法主要是用来进行探索分析的可视化手段与数据降维，但最近因为出现了一个绕不过去的数据问题就把主成分分析又拎出来看了一下，这才意识到这个方法其实四通八达，可以把很多数据分析的概念连接起来。&lt;/p&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;从线到点&lt;/h2&gt;
&lt;p&gt;首先还是回到一个最简单的场景，我有一堆数，想找出一个来做代表。从距离测量角度，就是找一个点让它离所有点最近，这就成了个优化问题，此时不同测量方法结论是不一样的。例如你考虑距离的绝对值最小，那你就会得到中位数；如果是差异的平方，求导后就是均值。回想下对一堆数找一个数，其实就是一种降维，从1维降低到0维。这里我们只考虑最小化差异的平方，那么求均值就是主成分分析把从1维降低到0维的应用场景。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;从面到线&lt;/h2&gt;
&lt;p&gt;现在复杂一点，我们设想一个二维（无码）平面，如果我们对其降维，那么降一维就是线，降两维就是点。而且我们可以确定降两维的那个点肯定就在降一维的线上，不然你这个降维就丧失了代表性。至于如何保障代表性，一般来说要交给数学家。那么这条线会通过所有点的均值，此时你应该想起来二维线性回归也通过这个点，那条线可以通过最小二乘得到，会不会就是我们要找的那条线？这个答案是否定的，最小二乘里最小化的是因变量到回归线的值，但是这里主成分分析最小化的是所有点到一条线的垂直距离，模型上细微的差别导致结果也会有区别，事实上求解过程也不对等。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;主成分分析的求解思想&lt;/h2&gt;
&lt;p&gt;虽然最小二乘回归线是高斯－马尔可夫定理下线性回归的最佳无偏估计，但主成分分析里二维降一维里那条线的求解思想并非回归到均值，常见有两种解释。第一种是寻找低维度空间，使投影点上到高维度点距离最近；另一种则是从统计角度寻找让点之间方差最大的方向映射，然后寻找跟这个方向正交的方向中方差最大的方向继续映射。从求解上，这两种解释都可转化成最优化问题，都是先归一化，然后求协方差矩阵，通过求导求特征向量跟特征值，那个方差最大的方向或距离最短子空间维度就是协方差矩阵里特征值最大的特征向量，剩下的方向或维度跟前面那个正交，再次找方差最大或距离最小即可。当然协方差矩阵不是一定要求的，如果你选用奇异值分解的套路就完全不用求。在这个求解策略下，解析解就是正交的，如果不是，那就不是主成分分析了。&lt;/p&gt;
&lt;p&gt;除此之外，理论上你也可以用隐藏变量模型迭代求解，不过有解析解不要用数值分析去逼近，而且有些矩阵运算可以进行分布式计算，这个在数据量大时是要特别考虑的。主成分分析求解上可以用矩阵是很大的优势，虽然理论上其概率解释并不完美。不同求解思想的多元分析方法其实背后都是有思想跟应用场景的，虽然理论上很多都是通用方法，但如果不适合你的数据就不要用。当前由于技术进步，之前很多很耗性能的方法目前都可以计算得到，如果搞科研我们要找那个最完美的，但工业应用可能更看重性价比。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;归一化&lt;/h2&gt;
&lt;p&gt;如果我们进一步考察三维空间，那么我们的降维就首先是一个平面，然后是平面上的线，然后是线上的点。此时如果你对所有数据点乘2，那么很自然点、线、面的坐标位置都要变化，这样你就可以理解一个事实，那就是主成分分析对尺度是敏感的，所以一般来说都要对不同尺度／维度的测量进行归一化，否则你的映射会被大尺度的维度带跑偏。到现在为止，我们可以大概对主成分分析有个直观感受：将高维度空间的点映射到低纬度空间的点且要保证这些点之间的差异关系最大程度地保留，至于怎么保留，不同求解思想实际求解结果一致，都可以用矩阵运算，内含了进行转换或映射时要沿着正交的维度走（使用了正定阵），所以求解完矩阵就可以得到符合要求的低维度空间，而且低维空间是正交的。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;投影点的方差&lt;/h2&gt;
&lt;p&gt;主成分分析经常用来可视化，这里我们回到二维平面降维的场景仔细看看我们究竟可视化了什么。首先我们有一个二维点A，这个点投影到一维线上得到点B，这个点跟所有点的均值C连线就是到0维的投影。目前我们已知AC这个线，同时A到一维线的距离又要最小也就是垂直，这样A、B及C构成一个直角三角形。此时根据勾股定理BC这个距离最大，也就是一维到0维时所有投影点的距离之和最长，在这个方向中各点间方差最大程度保留，也就是找到了方差最大的方向。事实上，因为前面提到的直角三角形，每降低一次维度，点之间的距离比高维度都不可避免的减少，如果此时点聚到一起不一定相似度很高，但如果主成分占总方差比重比较大，那么这些点就很有可能十分相似。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;多维标度分析&lt;/h2&gt;
&lt;p&gt;说到距离，其实主成分分析也是多维标度分析的一种。在经典多维标度分析中，测定点很困难，但可以测到点之间欧式距离并构建距离矩阵，因为其映射子空间里点之间方差最大时可以证明点之间的距离也是最大的，这个特性保证了当我们只有距离矩阵时进行主成分分析得到的低维映射也可以保证两个空间间距离最短，这样主成分分析事实上符合经典多维标度分析。也就是说，在你能够测到欧式距离而不是点时，是有可能重构出原始标度的，这点在结构生物学上有应用，但我完全不了解。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;概率化的主成分分析&lt;/h2&gt;
&lt;p&gt;主成分分析在求解上基本都走了矩阵运算的捷径，结果也是等价的。但这个过程不算是一个概率模型，因为可能产生不确定度的白噪音根本没出现在求解模型中。此时，我们应该意识到，这个子空间可能是某个概率模型的解，但如同我们只求了均值没求方差一样，似乎我们没有考虑模型的不确定度。这样我们需要从统计角度把主成分分析统一到基于统计学的数据分析中，这样也许会对将来构建相关假设检验模型有用，当然这也意味着我们可能不太方便再用矩阵运算来求解了。&lt;/p&gt;
&lt;p&gt;首先，我们对数据点进行假设，例如来自一个正态分布，那么主成分分析的问题就转化为求一个子空间，使得映射后的距离最小。让我们把这个映射关系描述成下面这样：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
t = Wx + \mu + \epsilon
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这里t是我们观察到的数据点，W是映射关系，维度不变可以理解成坐标轴旋转，x是映射后的点，&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;代表x的均值，&lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;代表高斯随机变量。这样我们看到的点符合均值&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;，方差&lt;span class=&#34;math inline&#34;&gt;\(WW^t + \psi\)&lt;/span&gt;的正态分布，这里&lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt;代表了随机误差，如果我们不考虑这一项，那么主成分分析是完全可以用特征值跟特征向量求解的，此时我们默认那个误差项0方差。但是，实际场景中我们都很清楚每一个高维样本点都至少存在测量误差，这个误差的方差不是0，那么此时我们应该在模型中包含误差项，但一个很尴尬的问题是我们对这个误差一无所知。此时我们假定所有点的误差项来自于某一个方差统一的正态分布，然后有了这个限制条件就可以求解了。加入了这一部分后，主成分分析就可以进行假设检验了，例如某个点是否属于异常值。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;em&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;EM算法&lt;/h2&gt;
&lt;p&gt;说到求解EM算法是绕不过去的，这个算法普适性比较强，存在隐藏变量的模型求解都可以用。主成分分析可以看作一种存在隐藏变量的模型，我们在低维空间看到的点背后是高维空间点但看不到，反之也成立。这样我们先随意假设一个新空间出来，这样我们就可以进行E阶段计算，也就是把看到的点投影到这个新空间上，然后计算距离。之后我们就可以进行M阶段，也就是最小化距离，这样就做出了一个比起始新空间距离更小的空间。然后再进行E阶段，M阶段，直到距离无法缩小。说白了就是模型不存在时先人工创造一个，然后不断按你的目标迭代让模型跟数据契合。在EM算法里，我们就可以很轻松把前面的方差项也扔进去一同优化，最后也能求解。这样概率化的主成分分析就有解了。不过这个算法具体实现存在很高的技巧性，我们吃现成就可以了。同时你会发现，其实EM算法思想可以用在很多不同模型参数求解上，马尔可夫过程、贝叶斯网络、条件随机场等有隐含变量的都可以用。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;因子分析&lt;/h2&gt;
&lt;p&gt;其实在更多资料中引入概率化的主成分分析主要是为了引入因子分析，因子分析跟概率化主成分分析最大区别在于其不限制误差来自方差相同的正态分布。这当然增加了计算难度，但其实因子分析对于解释这种隐藏结构其实比主成分分析更靠谱。但是，因子分析求解上不如主成分分析容易理解，需要通过一些方法来决定因子数或干脆使用者自己决定。此外，因子分析是可以进行预测的，目标就是潜在因子。从概率角度讲主成分分析自然也可进行预测，不过你得想清楚应用场景。同时，因子分析得到的成分也是正交的，这点跟主成分分析一致。正交的优点在于映射之间不相关，但不一定独立，如果数据分布需要独立因素就需要独立成分分析。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;独立成分分析&lt;/h2&gt;
&lt;p&gt;独立成分分析在独立成分符合正态分布时其实就是主成分分析，但当你独立成分并不来自正态分布时，独立成分分析就更有优势将其反推出来。因为独立跟相关是不同的，独立在统计学里比不相关约束条件更强，不相关不一定独立但独立一定不相关，独立因素间的互信息为0或者说高阶统计量上都不相关。最经典的应用就是鸡尾酒会问题，在一个嘈杂的场景里很多人都在说话，你在固定位置放了几个麦克风，这样麦克风收集到的就是多种声音的混合，现在你需要把混音中每个人的声音提取出来。此时你要用主成分分析，你会得到所有人声音的共性，但独立成分分析就可以分辨出每个个体，或者说潜在变量，所以你也猜到了，EM算法也可以求解独立成分分析。需要注意的是独立成分分析不管降维，基本你设定分多少个就有多少个。但不论主成分分析、因子分析还是独立成分分析，本质上都是线性模型的结构，也就是所谓的主成分、因子、独立成分都是原始数据的线性组合。&lt;/p&gt;
&lt;p&gt;在我看来生物组学数据更适合独立成分分析，你可以直接从数据中提取出一组独立模块进行注释，这样可以直接去关联生物学功能而不是反过来。当然你可能会说主成分分析或因子分析也可以做啊，但你如何保证其分布假设与正交假设？不过我们还是用主成分分析来说一下，因为很多人没意识到这个功能。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;聚类／共性／压缩／降噪&lt;/h2&gt;
&lt;p&gt;有些论文用主成分分析搞聚类画圈圈来说明样品间存在内在共性。这个在环境分析中比较常见，因为环境分析通常同时测定上百种化合物，前面提到低维映射里最大程度保留了样品点的差异，此时映射到一起就有可能说明那些样品污染特征接近，便于探索来源或环境过程。实际上此时不一定需要局限在主成分分析，可以直接用聚类分析等统计模型。&lt;/p&gt;
&lt;p&gt;很多人搞不清楚特征值、特征向量还有载荷等的细节，所以主成分分析就被用成了降维画图工具，但其实这个探索分析是针对背后隐藏变量的，具体到主成分分析就是共性。还是举个例子来说吧，我有100个样品，每个样品测了1000个指标，现在我就有了个&lt;span class=&#34;math inline&#34;&gt;\(100*1000\)&lt;/span&gt;的矩阵，通过主成分分析我得到了&lt;span class=&#34;math inline&#34;&gt;\(100*250\)&lt;/span&gt;的矩阵，这个矩阵包含了原数据95%的方差。好了，现在我问你，这250个新指标是什么？对，特征向量，特征向量就是新投影方向，投影可以看作隐含共性。特征值又是什么，共性的权重，越大代表越重要，毕竟可以代表更多的方差。那么载荷又是什么，大概可以理解成原来1000个指标对250个新指标的贡献。那么进行分析时我们在样本和指标之间多了一个共性层，一方面减少了数据维度，另一方面算是提取了指标间不相关的共性（但不一定独立，切记）。对于多出来的共性层，我们同时知道样品在这些共性上的分布，也知道每个指标对共性的分布，常见的biplot就可以同时绘制样品点跟指标在两个最重要共性上的分布，一目了然。此时我们的专业知识就要上场了，我们可能会通过指标相互作用发现共性背后对应隐含因素的物理含义，也可以发现某种分离样品的共性背后暗示的样品潜在来源。总之，多了一个共性层后，我们可以研究的机理就更明显了，例如自然语言处理里可以用其寻找文本主题，基因组学里可以用来寻找基因模块等。但需要提醒的是，这个“共性”并不代表客观规律，只是一种线性变换后的结果，如果跟实际想研究的因素不对应还不如直接上回归分析。&lt;/p&gt;
&lt;p&gt;主成分分析或者说实现主成分分析的奇异值分解的另一个应用就是可以用来压缩数据，上面的例子中100*1000的数据空间如果赶上稀疏矩阵十分浪费，此时就可以用奇异值分解压缩存储空间。从信号处理的角度去看，主成分分析跟傅立叶变换等变换过程本质上都是用一组新信号替代原来信号，由于一般认为信号方差高于噪音方差，通过变换时保留主成分或特定频谱，我们同时可以做到降噪。图形处理也可以用，而所有数据其实都可以用图形展示，那么作为图形降噪的主成分分析背后跟数据降噪是可以联系到一起的，特别环境痕量分析中的降噪。结合前面的结构重构、方差保留等性质，其实哪怕你就只会主成分分析，想明白了能做的事也很多。&lt;/p&gt;
&lt;p&gt;你只是需要一点想象力。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>科研博客圈的书剑恩仇</title>
      <link>/cn/2017/09/04/sci-blog-discussion/</link>
      <pubDate>Mon, 04 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/09/04/sci-blog-discussion/</guid>
      <description>&lt;p&gt;有人的地方就有江湖。&lt;/p&gt;
&lt;p&gt;推动科学进步的是学术争论，大家围坐一席以数据与逻辑为工具互相质疑，寻求共识。但事实上这个过程中并不缺乏个人或群体情感的介入，这一方面是现代科研职业化所导致的拿钱吃饭，另一方面则是科研人员自身的主观好恶。这一点在科学家的博客上展示的淋漓尽致，虽然在学术期刊里发评论比较正式，但在预印本、数据共享与可重复性研究的大趋势下，越来越多的科学家选择时效性更高的非同行评议的博客来对科学进展进行评论。借助这些社交媒体，我们也可以一窥他们对学术观点的爱恨情仇，也许有人不屑于这些主观性比较强的评论，但从学术交流的角度出发，如果我们仅仅通过学术期刊与会议交流学术观点，由于存在审稿与运作周期，很多共识会消耗大量的传播成本来达成，这不仅与信息时代脱节，也会造成资源浪费。下面我们看些案例感受下国外学术界在博客这一媒介上的观点交锋：&lt;/p&gt;
&lt;p&gt;案例一：“主观”的贝叶斯方法&lt;/p&gt;
&lt;p&gt;哥伦比亚大学的 Andrew Gelman 的博客可以算得上是个火药桶了，他本身主张贝叶斯学派，而赶巧贝叶斯学派跟频率学派可以算得上科研数据分析里哲学思想差异最大的两派，起码按我的粗浅认识是根本无法调和的，所以即便实用上甚至算法上都差异不大，想对这两种思想和稀泥基本都会被 Gelman 教授无情嘲讽，如果你还打算说贝叶斯不好，基本上会被博文讨伐。当然，也不是所有人都有这个待遇，同舟子的做法类似， Gelman 教授基本也是逮着大鱼去坑。需要提醒的是他可不是舟子那种十几年不做科研的学术圈外人士，其本人是哥伦比亚大学应用统计中心的主任，其团队的研究领域十分广阔，大家可以感受一下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;why it is rational to vote; why campaign polls are so variable when elections are so predictable; why redistricting is good for democracy; reversals of death sentences; police stops in New York City, the statistical challenges of estimating small effects; the probability that your vote will be decisive; seats and votes in Congress; social network structure; arsenic in Bangladesh; radon in your basement; toxicology; medical imaging; and methods in surveys, experimental design, statistical inference, computation, and graphics.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;顺带一提，著名贝叶斯统计软件 stan 就出自这个团队。&lt;/p&gt;
&lt;p&gt;这次事情的起因是卡内基·梅隆大学的 Larry Wasserman 教授（2016年当选美国国家科学院院士）在接受一个博客&lt;a href=&#34;https://errorstatistics.com/2013/12/28/wasserman-on-wasserman-update-december-28-2013/&#34;&gt;采访&lt;/a&gt;时对频率学派与贝叶斯学派下了个定义：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I wish people were clearer about what Bayes is/is not and what frequentist inference is/is not. Bayes is the analysis of subjective beliefs but provides no frequency guarantees. Frequentist inference is about making procedures that have frequency guarantees but makes no pretense of representing anyone’s beliefs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Gelman 教授对其频率学派的观点没啥意见，但那个 “subjective” 直接引爆了火药桶。而按照 Gelman 的定义，贝叶斯方法应该是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Using inference from the posterior distribution, p(theta|y)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;特别的，他还认为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Science is always full of subjective human choices, and it’s always about studying larger questions that have an objective reality.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;坦白说这个看法是比较符合科学史的，虽然当今科学理论体系逻辑上相对完备（先排除下哥德尔跟量子力学），但其发展确实很曲折，在实验数据跟统计决策成为主流之前，很多理论在发现或提出时主流科学家并不接受，有的是逻辑上不接受（很多新理论完全不容于旧理论），有的则属于威权集团打压，可以说相当主观。&lt;/p&gt;
&lt;p&gt;但在后面的论述中，Gelman 教授就开始开嘲讽技能了，Larry 认为在高维数据处理中贝叶斯方法没意义无法解释，Gelman 教授则反驳说他觉得除了贝叶斯方法别的方法也都是解释不通的，并且他认为 Larry 自己不懂贝叶斯还瞎定义是十分不妥的。不得不说这段论述很没营养，跟小学生吵架差不多。紧接着 Gelman 教授又提到主观确实是贝叶斯方法的一部分但不是全部，那频率学派是不是可以说成“简单随机采样的技术”，科学研究范围在拓展，各种方法也在发展，贝叶斯方法可以研究客观问题。这个说法也比较中肯，接下来 Gelman 教授又开启了挖坟模式，他把 Larry 08年到13年关于贝叶斯方法中随机性看法的转变给列了出来，紧接着又说我也有这个转变过程。但文章最后他又翻了 Larry 对经济学家的旧账，认为他存在个人偏见。&lt;/p&gt;
&lt;p&gt;看起来这个文章似乎比较正常，但这篇博文真正有趣的是评论，基本上集中了当今统计学中各路高手，下面是个不完全名单：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nick Cox 杜伦大学 Stata 元老级开发者&lt;/li&gt;
&lt;li&gt;Larry Wasserman 卡内基·梅隆大学教授 当事人&lt;/li&gt;
&lt;li&gt;Deborah G. Mayo 宾夕法尼亚大学教授 采访 Larry 的人 errorstatistics.com 博主&lt;/li&gt;
&lt;li&gt;Kevin Dick 斯坦福毕业 创业者 possibleinsight.com 博主&lt;/li&gt;
&lt;li&gt;Judea Pearl UCLA 教授 &lt;a href=&#34;http://causality.cs.ucla.edu/blog/&#34; class=&#34;uri&#34;&gt;http://causality.cs.ucla.edu/blog/&lt;/a&gt; 博主&lt;/li&gt;
&lt;li&gt;Christian Hennig 伦敦大学学院教授&lt;/li&gt;
&lt;li&gt;Norm Matloff UC Davis 教授&lt;/li&gt;
&lt;li&gt;Brendan K O’Rourke 都柏林理工教授 &lt;a href=&#34;http://www.brendankorourke.com/&#34; class=&#34;uri&#34;&gt;http://www.brendankorourke.com/&lt;/a&gt; 博主&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以看出这么几件事：首先，这些领域内专家会互相关注对方的个人网站并通过这种方式互动；其次，看他们的讨论很有启发，必看书本上的干货更有意思；再次，很多讨论虽然对问题是没营养的，但有助于我们了解一些学术界的风格或流派。在前沿领域由于知识不全，多数情况是无法达成共识的，但通过了解其流派风格会帮助你更全面的看问题。&lt;/p&gt;
&lt;p&gt;案例二：两个软件会产生一个结果吗？&lt;/p&gt;
&lt;p&gt;巴拉巴西是一位呼声很高的诺奖候选人，其畅销书《链接》可以说把不少科研人员吸引到了网络科学的研究领域，现实中的无尺度网络的幂律分布所具有的奇特性质在很多并不相关的领域都有展示。但这个故事主角不是他，提到他只是想提前表示下同情，因为他在加州理工教授 Lior Pachter 的博客里躺枪了。事实上，2014年 Lior Pachter 在博客上开了个三部曲，本意就是对 MIT 教授 Manolis Kellis 的个人恩怨，但为了把故事讲的通透点，这位老兄追根溯源并展示了自己强大的数理功底，先后对两篇发表文章的创新性进行质疑，从图表到算法，其中一篇就是巴拉巴西的，另一篇则是 Manolis Kellis 教授的。这个故事科学网薛宇老师曾经翻译评论过，我这里不细讲。但 Lior Pachter 教授在后续的博文中又对号称H指数100多的巴拉巴西来了次二次扒皮，严格说被炮轰的其实不算冤枉，但被人挂的如此直白也只有 Lior Pachter 教授能做得出来。而我今天要讲的是他最近又跟纽约大学石溪分校&amp;amp;哈佛&amp;amp;卡内基·梅隆大学的同行掐架了，上演了进攻-防守-再进攻的三部曲。&lt;/p&gt;
&lt;p&gt;首先 Lior 讲在他们那个 RNA 测序定量的圈子里，软件跟软件差异都是很大的，基本你用不同软件想得到一样的结果非常困难（这也说明这个领域的研究共识没有达成）。然后他话锋一转，说自己组里2016开发的一个软件跟最近发表在 Nature Methods 上的软件处理结果却出奇的一致，皮尔逊相关系数三个九，然后又是一通追根溯源。这里岔开说一句，Lior 之所以可以追根溯源，是因为预印本及版本控制系统的流行，最近 ACS 也对化学领域提供了预印本服务，预计不久就会覆盖绝大多数涉及数据分析的实验学科。从版本上 Lior 发现在他们论文发表后 Rob Patro 的软件也有了一个很大的更新，更新前跟他们组软件差异明显，更新后确几乎一样了，最后他认为 Rob Patro 所发表的文章实际上就是抄了自己组里开发软件的思想，然后加了个矫正。当然 Rob Patro 也很快在 github 上发表了一个回应，大意是他们在文章跟源码中多次引用了 Lior 组的论文并且在有些数据集中这两个软件的结果是不一样的，工作流程也不一样。但 Lior 教授显然并不满意，他又写了一篇博文指出其回复混淆视听，所谓的不一样是下游分析，而在 RNA 定量上这两个差距还是很小，如果你去看这篇回复会发现 Lior 甚至使用了动画来展示两者区别很小，可谓精心准备。我在读这三篇文章时学到很多的论述方法与追踪验证方法，可以说很多方法现在还没出现在教科书中，但可以感到早晚会形成趋势。&lt;/p&gt;
&lt;p&gt;凭心而论， Rob Patro 的文章就算是对 Lior 软件的改进也是值得发表的，因为当前科研基本都是N+1模式，都是在前人基础上做功课。但我也比较理解 Lior 为什么这么火大，首先在他眼里这两个软件本来就是一回事，凭什么发 Nature Methods，他自己那篇都没发这么好，另一方面就是 Rob Patro 文章在他看来有硬伤，速度也不快，效果也没那么好，评价标准还有问题。其实说白了也有点个人恩怨而不是就事论事，但在这些问题上你去要求当事人一碗水端平也很难。如同第一个案例所言，科学研究就是会掺杂各种主观情感，但作为旁观者，我们可以从中去学习他们讨论问题的方法，例如 Lior Pachter 教授的论证过程，虽然不如发表文章里那么逻辑完备，但思考步骤都是比较清晰的，而这个过程你在期刊论文中往往看不到，好比你看到的总是对方站在山顶但怎么爬上去的一般都不会写，但有时候这些看似琐碎的步骤却足够让你永远达不到那个高度。&lt;/p&gt;
&lt;p&gt;顺带一提， Lior Pachter 教授的博客上还友情链接了 Andrew Gelman 教授的博客。我想说的是在国外是真真切切存在着通过博客的学术交流的，参与学者的水平也是相当强悍，而且不同于国内科研向公众号或博客满足于对论文的解读，这些博客上更多出现的是一种批判式讨论，而且夹杂了相当重的个人情绪，如果你打算阅读也是需要辨伪存真的，这本身对于提高科研思维也有帮助，所以我推荐高年级本科生、研究生跟科研一线的学者都可以去寻找自己感兴趣领域大牛的博客，省的每次找推荐审稿人都搞近亲繁殖，如果你能从这些火药桶博客里获得正面评价，那么恭喜你，科研对你并不是个坑。&lt;/p&gt;
&lt;p&gt;其实类似的故事还有很多，你可以从这篇文章里出发用关键词去探索。我在前面的文本分析的文章中曾提到越是高端的论文，发表勘误的比率就越是很高，这说明前沿领域的研究不确定性是很高的，思想碰撞也很激烈。如果把社交媒体上的各类花式吐槽也算进去，你会发现科研领域有很多烧脑的故事，各路参与者也从来都不缺名校光环跟牛文加持，阴谋诡计、解释掩饰、爱恨情仇等可能被小心翼翼地埋藏在数据与图表之中，虽然看懂需要比较高的门槛，但也正是这种门槛屏蔽了围观群众，上演一幕幕精彩绝伦但需要自行判断的书剑恩仇。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>唐提保险、区块链与个性化</title>
      <link>/cn/2017/08/07/tontine-insurance/</link>
      <pubDate>Mon, 07 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/08/07/tontine-insurance/</guid>
      <description>&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;唐提保险&lt;/h2&gt;
&lt;p&gt;在纽交所还没成立时，活跃在华尔街的经纪人业务并不像今天这样职业化，他们基本接受各种代理业务，其中有一种名为唐提的养老保险特别受欢迎，规则简单到一句话就可以说清：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;所有参与者投资，一段时间后幸存者获取所有资金的收益。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;举例而言，10个人每人出1000块，约定10年保险期然后把10000块交给投资人打理，许诺收益率6%，这样每年投资人会拿回600块利息，然后刚开始是10个人分每人60块，到了第五年，有4个人过世，投资人收益将由幸存者分，也就是每人100块。当然也可以不约定保险期，直到最后一个人过世为止，在那之前最后的幸存者独享每年600块的收益。至于本金可以在约定时间后留给死者后代或也留给那个幸存者，如果持续将后代也算进来那么理论上这种保险可以持续运行很久，直到某个家族完全消失，然后幸存家族的份额会得到提升。&lt;/p&gt;
&lt;p&gt;这种保险形式非常特别，因为买这个保险完全不需要精算群体死亡率，只要看懂规则愿意加入就可以，甚至完全不需要保险公司来中介。从某种意义上，这是一种混合了分红与赌博的产品，只要你赌自己可以活的长就行了，保险成本的负担从整体转嫁给了个人。事实上美国就有类似的教育储蓄产品，家长拿出一大笔钱放到银行一年后转回本金，然后大量本金产生的利息将作为子女完成高中教育后上大学的分红，但只有考上大学的人才能参与这笔分红。对每个人而言，整体入学率或死亡率都是没有太大意义的，只要你敢赌自己考得上或能活下来，那么就可以参与这个博弈。作为博弈的管理者也毫无精算风险，只要专注于许诺的收益率就可以了，不用担心投保人大量报案导致的高风险。其实诸如意外险、财产险甚至运费险背后都有这种逻辑，那就是让受害者而不是幸存者收获非受害者的本金。&lt;/p&gt;
&lt;p&gt;从历史上看，最早提出概念的Lorenzo de Tonti 是建议用这种方法来为法王路易十四筹集军费，后来英国也采用过这个方法，他们给出的年利率都不低于10%。但100年后国家层面的唐提保险就消失了，不是因为幸存者之间互相残杀引发的道德问题，而是参与这个保险的人平均幸存率太高，结果国家层面许诺的利率又达不到，所以就维系不下去了。其实这些国家本来是给不出10%的利率的，但如果参与者不断有人离世，那么这个利率就可以维持，结果倒霉的是参与者似乎都很长寿（有些是通过欺诈），然后仅是维持许诺利率都让国家不堪重负了，最后无奈把这个保险转成了年金制。后来这个保险跑到了美国成了一种退休金并开始流行，到上世纪初，这种保险的规模甚至达到了美国总财富的7.5%。事实上，当时4%年收益的唐提保险实际上可以对投资者产生10%的收益。不过，到1904年这种形式就被禁止了，主要问题是保险公司利用这一制度短期聚集了大量资金并且20年内不交代用途只考虑分红，同时就是投资者死亡后面临本金无法赎回的道德问题。所有的参与人都希望自己活得长的另一个说法就是所有参与人都希望别人活的短，这甚至给美国文学作品创作提供了灵感。&lt;/p&gt;
&lt;p&gt;事实上，直接形式的唐提保险虽然被禁止，但间接形式的唐提保险一直存在，在以色列集体农场中，一直都有农场共同基金是采用唐提保险形式的，这样作为集体的财产可以一直保留在集体中而不是伴随遗产外流。但最近几年，美国又有人提出唐提保险可能是一种很好的养老金形式，促成这个想法的技术趋势就是区块链。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;区块链&lt;/h2&gt;
&lt;p&gt;区块链算得上一个被IT行业炒烂的概念，跟它一组的还有：共享经济、大数据还有知识付费。我最近读了下中本聪那篇论文，说实话被震撼到了，并不是说看好比特币投机而是看好这个技术的巧妙设计，用同样的构架可以做很多事。下面我就大概说下核心概念：&lt;/p&gt;
&lt;p&gt;如果我打算从市场买一个产品，付款后得到产品，然后作为媒介的钱究竟怎么来怎么去我并不感兴趣。但现在我告诉你存在一个公开的账本，所有交易的细节都可以广播后从所有人的账本上查到，这样你可以追踪你的货币到其铸造出的那一刻，而货币的铸造则是一个对大量交易打包封装成区块过程的验证奖金，最先验证成功的区块发出广播，所有的账本都会加入这个区块。也就是说，这是一个分布式造就的整体权威而非中心化的，如果活跃账本中多数先收到验证成功的广播，那么这就是主链区块。同时，基于数学特性，几乎不可能有人能小范围打包多个区块来声明更多的货币，因为这样即便延长了小范围的区块链但也不能被其他人认可，后果就是那个链成为废链。同时，所有交易是基于地址的，而这个地址根本不需要权威验证身份，也就是同时做到了匿名与公开，所有人从公共账本里看到的都是地址间的交易，但地址属于谁是无法得知的，因为这样的地址可以无限生成且互相交易，一换手就没办法查了。这也就是为什么今年上半年勒索病毒要求比特币作为赎金，我们也能基于地址查到多少人交了赎金，但就是不知道地址主人是谁。&lt;/p&gt;
&lt;p&gt;那么这跟唐提保险有什么关系呢？唐提保险当初被人诟病很大程度是因为这可能是个熟人间的保险，大家相互认可才签协议，举例而言你不想跟个婴儿签共同的唐提保险，其大概率会成为最终的幸存者，但如果大家相互认识就存在道德问题了，那就是有些人可通过谋杀另一些人来获利。但如果用区块链技术，我们可以匿名参与唐提保险，而由于你是一个区块链用户，我们可以追踪你在区块链上的活动来确认你是否符合参与保险的条件，例如在区块链设计中加入每天步行数上传或心率数据上传的设计，那么只要你活在可追踪的区块链中，唐提保险就会不断分红直到你的区块链活跃度为零。这样道德风险就几乎为零了，因为所有人都不知道谁在参与。同时唐提保险可以设计为无数条链，每条链人数固定，只有同一条链上的人可以凭借自己特有的地址不断收到作为分红的代币，只要保险公司或代币市场可以将其转为法币，那么这个游戏就可以悄无声息的运转，即使你知道别人也在游戏中但因为可能不在一条链上而没有利益冲突。其实这个机制可以很好的回答另一个问题：大数据下的个人价值。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;个性化&lt;/h2&gt;
&lt;p&gt;如果你的行为数据可以被收集用来预测寿命，一个生活习惯良好无不良嗜好的人基本不需要买保险或价格很低，留个遗嘱就可以了；而那些抽烟且有酒驾记录的人想买也会因为价格过高而无法负担。这其实对行业是不利的，保险行业里想买的需要那些不需要买的来共同承担风险，但如果我通过自测发现不需要买，那我很有可能就不加入，结果保险保的都成了高风险的人，最后也会入不敷出。技术上其实越来越允许数据持有者了解并预测自己的行为，巴拉巴西在《爆发》中提到，93%的人类行为可以预测，配合精准医疗技术，未来很多人可能很轻易的知晓自己的行为与最佳生存模式，这种情况下的危机就是人不会主动参与共同抵御危机。举例而言，如果你不可能患罕见病就无所谓购买相关保险，但罕见病患者则可能成为商业规则下被忘记的一批人，无利可图所以没有人关心，市场就是这样。越是精准的营销策略其实越不需要营销，因为你想让人买而那个人其实本来就想买，找到人就OK了。但这事实上会造成不平等，你的价格可能是量身定做的，但往往却是无法负担的。这样的不平等在我看来是可以通过技术来解决的。&lt;/p&gt;
&lt;p&gt;在数据时代没有隐私，但隐私的价值却是变化的。如果存在一种算法，可以综合个人各种风险就可能解决信息不平等。举例而言，A喜欢极限运动但身体健康，B生活规律但带有癌症基因，也就是说A需要意外险不需要重疾险，B需要重疾险而不需要意外险，如果两种保险去卖估计都只能卖出去一份且价格偏高，但是如果A跟B是一组去买两人都可以得到保险且由于卖出两份边际成本会下降则价格不高。如果把一个人一生的动态风险不断打包整合到一个区块链上，综合风险类似的人出现在同一条链上而且不同区块链可以动态转接进行风险控制，保险公司收费后只要在不同风险的链上定期注资，概率上一定有人收益，这样所有人可能都乐于加入这样一个计划，只要你不是一个全面极端的人，在一点上的极端是可以被另外多点的不极端而中和掉。运行这样一个区块链系统同样并不需要实名，只要你乐意加入就够了。你总是会不断出现在跟你综合风险类似的人的链条上，由于你并不清楚对方实际哪方面有风险，实际我们可以引入唐提保险机制，这样可以保证参与度与整体系统的稳定性。这个机制的优点在于每个人即使对自己一清二楚也总能找到一个跟自己类似但细节完全不同的人进行生存游戏，每个人在算法公平下其实也实现了共同保险，而且算法够强的话没有人知道你具体是谁。&lt;/p&gt;
&lt;p&gt;本着个人谋求私利的心降低整体风险，这是对算法技术的新要求，没必要寄托在慢半拍的政治、经济、法规跟伦理上，新的技术与博弈机制可能最终会解决社会风险问题。而个人隐私其实也成了未来每个人的生存筹码，毕竟天天在家里宅着看视频就不太可能被毒蛇咬到，那就找个野外科考队员来分担你II型糖尿病的风险吧，虽然你的数据被泄漏了，但也从某种方面证明了其价值，当这一切被配对整合后，大家都应该可以过自己想要的生活而不用过多担心风险。&lt;/p&gt;
&lt;p&gt;技术产生的问题还是要技术来解决，反正魔盒已经开启。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;参考文献&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.amazon.com/gp/product/B00WMRPWVG/ref=as_li_ss_tl?ie=UTF8&amp;amp;btkr=1&amp;amp;linkCode=sl1&amp;amp;tag=kitcescom-20&amp;amp;linkId=0d2632884eb0eff4608787c0f4f3d660&#34;&gt;King William’s Tontine&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://bitcoin.org/bitcoin.pdf&#34;&gt;Bitcoin: A Peer-to-Peer Electronic Cash System&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.kitces.com/blog/tontine-agreement-instead-of-annuity-lifetime-income-mortality-credits-and-book-review-of-milevsky-king-williams-tontine/&#34;&gt;Could A Tontine Be Superior To Today’s Lifetime Annuity Income Products?&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.nytimes.com/2017/03/24/business/retirement/tontines-retirement-annuity.html?_r=0&#34;&gt;When Others Die, Tontine Investors Win&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>从真空里的球形鸡到社会财富分配（二）</title>
      <link>/cn/2017/07/29/%E4%BB%8E%E7%9C%9F%E7%A9%BA%E9%87%8C%E7%9A%84%E7%90%83%E5%BD%A2%E9%B8%A1%E5%88%B0%E7%A4%BE%E4%BC%9A%E8%B4%A2%E5%AF%8C%E5%88%86%E9%85%8D%E4%BA%8C/</link>
      <pubDate>Sat, 29 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/07/29/%E4%BB%8E%E7%9C%9F%E7%A9%BA%E9%87%8C%E7%9A%84%E7%90%83%E5%BD%A2%E9%B8%A1%E5%88%B0%E7%A4%BE%E4%BC%9A%E8%B4%A2%E5%AF%8C%E5%88%86%E9%85%8D%E4%BA%8C/</guid>
      <description>&lt;p&gt;前面说到在一个理想自发交易的稳态环境下，社会财富的分配会符合小球模型里的玻尔兹曼分布：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f(E) = A e^{-E/E_c}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;在这里，&lt;span class=&#34;math inline&#34;&gt;\(E_c\)&lt;/span&gt; 代表了温度，可以对应经济系统里总体财富的平均水平；&lt;span class=&#34;math inline&#34;&gt;\(E\)&lt;/span&gt; 代表了个人财富水平。这是个描述概率的指数函数，个人财富越多，越不可能出现。不过其实更多人熟悉的是财富分配的二八法则，也就是帕累托-齐普夫定律，那么这个定律又是什么鬼？跟玻尔兹曼分布又有什么区别呢？&lt;/p&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;二八法则&lt;/h2&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>从真空里的球形鸡到社会财富分配（一）</title>
      <link>/cn/2017/07/24/boltzmann-distribution-1/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/07/24/boltzmann-distribution-1/</guid>
      <description>&lt;p&gt;曾经有个笑话吐槽物理学家研究鸡不下蛋问题时首先假设了一只存在真空中的球形鸡，进而认为理工类研究过于简化了现实世界，再进而推导出了一种不修边幅、不谙人情世故且高智商低情商的理工科书呆子刻板印象。就我个人生活经验而言，这种看法倒也没啥问题，对，就是没啥问题，你没看错。&lt;/p&gt;
&lt;p&gt;但是（说“但是”前的都是废话–马克·于瘟），当今学术研究的一个大趋势就是用理工科的思维研究社会自发行为，我曾经尝试&lt;a href=&#34;http://blog.sciencenet.cn/blog-430956-869450.html&#34;&gt;用马尔可夫过程解释社会阶层流动&lt;/a&gt;，但其实很多理工科出身的科学家是很严肃地研究这类问题的。我们将会看到一个松散假设下的物理模型是可以解释很多（但绝不是全部）自发的宏观社会行为的。在某些视角下，我们也许就是个真空中的球状社会信息综合体。首先，我们从具象到抽象，来了解下一个统计物理学的概念——玻尔兹曼分布。在后续的文章中我们会用这个分布来探索下社会行为，特别是经济行为。&lt;/p&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;社会行为的抽象&lt;/h2&gt;
&lt;p&gt;社会行为其实就是个体间的相互作用，在物理学视角下，这个个体间相互作用有四种（但我知道多数人不关心这个），简单说就是物质能量交换。而社会经济行为视角下，这个相互作用可以看成价值流动，通俗一点就是钱。钱可以在流通成本很低的现代信息社会下快速在社会个体间转移，在物理学视角下可看作能量在不同粒子间的传递。那么类比一下我们会发现，如果我想知道一个社会整体的财富分配，我们可以类比到一个装满带有能量的小球的空间去观察小球的能量分布。这里有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;社会个体（人、公司、团体）-&amp;gt; 空间里的小球&lt;/li&gt;
&lt;li&gt;财富（钱、资产） -&amp;gt; 能量&lt;/li&gt;
&lt;li&gt;价值交换（买卖行为、资本流动）-&amp;gt; 小球间能量交换&lt;/li&gt;
&lt;li&gt;社会个体的财富分配 -&amp;gt; 空间里的能量分布&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里我们需要一些假设，首先我们考虑的是一个热力学平衡，也就是说，空间里能量总和一定，也就是要是个封闭空间，同样，社会里总财富在某个时间点也是稳定的。其次，我们想知道的是财富分布或能量分布，那么我们就要有不同财富区间与能量区间来构成分布，这里我们用钱数或能量值来划分，拥有钱数或能量在同一区间的社会个体或小球在分布中是一样的，无法区分，也是等概率的。最后，能量交换或价值交换要达到热力学平衡，这个在小球模型里很容易实现，但社会实际状态只能近似认为达到，这意味着交易是随机的且充分的，后续我们会修改这个限制让模型更符合社会实际。&lt;/p&gt;
&lt;p&gt;根据上面的类比与假设，目前我们大概可以用一堆小球去模拟一些稳态社会行为了，这个抽象过程是大多数理工类科学研究的起点，不然一上来就过于复杂很难讨论。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;封闭空间里的赋能小球&lt;/h2&gt;
&lt;p&gt;好了，目前我们先不去想复杂的社会行为来考虑小球。在一个封闭空间里，小球的能量总和是固定的，但能量范围却可以很广，小球数也可以很多，那么我们再简化下，就考虑3个球总能量6，能量区间就会有7个离散数值：0，1，2，3，4，5，6，7。那么我们想得到的是宏观状态下能量分布，我们首先来个原始方法：数。&lt;/p&gt;
&lt;p&gt;首先要数下有多少个宏观态。例如有一个球上有6的能量，其余的球能量都只能是0。我们可以列出下面的7种宏观态：&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-1&#34;&gt;Table 1: &lt;/span&gt;Macrostate.&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;0&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;4&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;5&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;6&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Macrostate1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Macrostate2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Macrostate3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Macrostate4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Macrostate5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Macrostate6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Macrostate7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;然后我们考虑每一种宏观态下有多少种微观态，因为球有3个，区间有7个，我们可以看成一个排列组合问题。微观下，一共有&lt;span class=&#34;math inline&#34;&gt;\(3!\)&lt;/span&gt;种排列组合，但在基本假设中，我们认为属于同一宏观状态的球是一种，那么这些情况就要被排除掉。例如在宏观态7中，虽然球可以有6种排列，但因为都在1个能量区间，实际只有1种微观态。也就是说，如果我们有N个球，排列组合上看虽然有&lt;span class=&#34;math inline&#34;&gt;\(N!\)&lt;/span&gt;种组合，但实际由于N个球中有n个球在区间i，我们要从总的排列组合中除掉这种组合。也就是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\# microstates = \frac{N!}{n_0!n_1!...n_i!}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这样我们可以得到共计28种微观态，在这里所有微观态的出现概率是一样的：&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-2&#34;&gt;Table 2: &lt;/span&gt;State.&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;0&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;3&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;4&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;5&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;6&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Microstate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Macrostate1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Macrostate2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Macrostate3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Macrostate4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Macrostate5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Macrostate6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Macrostate7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;total&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.75&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.64&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.54&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.43&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.07&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;28&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在宏观态1中所有微观态出现的可能性为&lt;span class=&#34;math inline&#34;&gt;\(3/28\)&lt;/span&gt;，其中针对能量为0的区间贡献&lt;span class=&#34;math inline&#34;&gt;\(2*3/28 = 0.214\)&lt;/span&gt; 个小球，而宏观态2中对能量为0的也贡献&lt;span class=&#34;math inline&#34;&gt;\(0.214\)&lt;/span&gt;个小球，同样宏观态3中贡献为&lt;span class=&#34;math inline&#34;&gt;\(0.214\)&lt;/span&gt;个小球而宏观态4中贡献为&lt;span class=&#34;math inline&#34;&gt;\(0.107\)&lt;/span&gt;个小球，这样会有&lt;span class=&#34;math inline&#34;&gt;\(0.75\)&lt;/span&gt;个小球贡献给能量为0的区间，同样我们可以得到其他能量区间上有多少小球。这个小球的能量分布就是我们打算求的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../cn/2017-07-24-boltzmann-distribution-1_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;在这个演示里，能量分布似乎跟数目是线性的，但是如果我们把系统放宽，加入更多的球跟能量，这条曲线应该是指数分布的且指数为负。当然我知道你们不信，这里我们用 Eisberg &amp;amp; Resnick 在量子物理教材中描述来进行一个理论推导。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;能量分布的数学形式&lt;/h2&gt;
&lt;p&gt;如果我们看到两个小球，这两个小球来自同一个能量分布，那么一个小球其出现在&lt;span class=&#34;math inline&#34;&gt;\(E_1\)&lt;/span&gt;上的概率为&lt;span class=&#34;math inline&#34;&gt;\(f(E_1)\)&lt;/span&gt;，出现在&lt;span class=&#34;math inline&#34;&gt;\(E_2\)&lt;/span&gt;能量区间上的概率为&lt;span class=&#34;math inline&#34;&gt;\(f(E_2)\)&lt;/span&gt;。我们考虑一个特殊情况，一个小球来自&lt;span class=&#34;math inline&#34;&gt;\(E_1\)&lt;/span&gt;而另一个来自&lt;span class=&#34;math inline&#34;&gt;\(E_2\)&lt;/span&gt;，发生这种情况的概率应该是两个概率的乘积，也就是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f(E_1) \times f(E_2) 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然后，我们考虑所有宏观态中能量为&lt;span class=&#34;math inline&#34;&gt;\(E_1 + E_2\)&lt;/span&gt;的情况，因为我们进行了区间划分，所以能量为&lt;span class=&#34;math inline&#34;&gt;\(E_1 + E_2\)&lt;/span&gt;的情况只出现在所有能量和为这个数的小球组合里。由于我们之前假设了所有微观态是等概率的，那么出现这个能量和的小球组合方式也是等概率的。那么在某种程度上，会有下面的公式成立：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f(E_1)+f(E_2) = h(E_1+E_2)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;我们可以认为上面那个特殊情况，也就是一个小球来自&lt;span class=&#34;math inline&#34;&gt;\(E_1\)&lt;/span&gt;而另一个来自&lt;span class=&#34;math inline&#34;&gt;\(E_2\)&lt;/span&gt;的概率是属于&lt;span class=&#34;math inline&#34;&gt;\(E_1 + E_2\)&lt;/span&gt;这个能量分布的，那么根据第一段的推理出现这个情况时的概率应该是乘积。也就是两个能量和的出现概率既是两个独立能量区间概率的和又是乘积，那么满足这个条件的数学形式只能是指数形式。那么我们可以得出，在某个能量区间上小球的概率密度函数应该是：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f(E) = A e^{-E/E_c}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这里面的常数&lt;span class=&#34;math inline&#34;&gt;\(E_c\)&lt;/span&gt;是描述独立于小球的系统变量，玻尔兹曼经过推导得出这一部分是系统温度（总能量）的线性函数，所以我们就有了玻尔兹曼分布的数学形式：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f_b(E) = A e^{-E/kT}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这个分布描述了在封闭系统内不同能量的小球概率分布形式，简单说就是能量高的概率很低，而能量低的概率比较高。这个现象是客观存在的，但同时由于存在量子效应限制，有些能量段上的小球是无法稳定存在的，所以能谱分布实际并不连续，不过这就是另一个故事了。那么这个符合粒子运动的物理模型跟社会行为有什么联系呢？&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;社会行为&lt;/h2&gt;
&lt;p&gt;在一个达到平衡的社会经济系统中，我们对小球的假设基本是符合现实的，能量代表财富，那么很直观的现象就是这个社会的财富分配天然就不是平均的，会基本符合指数分布。也就是说，总是少数人富有而多数人穷。那么有人会反对说发达国家都是纺锤形的，明显模型有问题。没错，发达国家可以是纺锤的，但如果把全球看成一个缓慢增长的经济体，一个区域特别稳定富有只可能是牺牲其他区域的财富增长才能实现。所谓共同富裕，在全球封闭尺度下是无法自发形成的。这里看起来跟自由市场理论有矛盾，在自由市场下，看不见的手可以调节保证一个健康的经济发展，但在小球模型里经济并不发展，只是自由分配与交易。不过换句话，在经济停滞后的交易行为应该会导致更极端的财富分配。至于说自由市场里的自发交易可以促进合理的财富分配，我觉得比较扯，更靠谱是富有者所承担的社会文化压力，要不然亚当·斯密也不至于再去写一本《道德情操论》。&lt;/p&gt;
&lt;p&gt;此外，请注意关键词：自发。也就是说不进行法律政策干预，但是如果博弈规则发生改变，那么物理系统就不那么好使了。另一个关键词是稳态，也就是如果社会整体财富增加了，那么即使分布不变，所有人生活的幸福指数也会提高。而增加社会整体财富的方式在最近这一百年的主要表现方式是科技革新，有意思的是，目前可以让财富分配更不平等的最主要动因也是科技的不平等。&lt;/p&gt;
&lt;p&gt;在接下来的两篇中，我们先看看到底这个世界的财富在不同的小球模型中会有如何的分布特征，然后再看看社会财富实际是如何分配的而物理学规律能给我们什么样的启发。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>文献阅读的文本分析流派</title>
      <link>/cn/2017/06/16/nlp-literature/</link>
      <pubDate>Fri, 16 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/06/16/nlp-literature/</guid>
      <description>&lt;p&gt;读文献是科研人员的基本功，一方面是了解学科发展，另一方面更现实一点，就是为了发文章。起步阶段读论文一般是模仿与学习，但到了中后期如果你的视野不够开阔，很容易陷入到安全区陷阱，认为自己做自己那一小摊就挺好，其实很有可能大浪过来，全军覆没，说直白点就是申不到钱，课题与项目运转不下去，思路也会枯竭。当你去开学术会议时，那些大会报告的报告人的开场总有个全局概览的视野，这种评论是需要经验去堆的，但其实也挺虚的：你回头去看容易知道哪里有坑哪里有丘，但身处时代浪潮之中是不太容易感知趋势的。&lt;/p&gt;
&lt;p&gt;但传统基于核心关键词的检索跟全局观是本质相悖的，核心关键词往往限制了内容，虽然有利于聚焦但不利于发散与概览。不过当前文献数据空前开放，如果你有类似全局视野问题，是可以自己探索的。这里要用到一个名为自然语言处理（NLP）的工具，简单说就是我不去看单篇文献或荟萃分析，而是通过语义关系探索大量文献中的潜在模式，进而找出热点。今天我用pubmed这个免费的文摘数据库来做个演示，探索下科学研究的整体前沿，结论不一定对，但方法思路如果你能掌握并举一反三，会有发现新大陆的感觉。&lt;/p&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;数据获取&lt;/h2&gt;
&lt;p&gt;数据获取思路是这样的：如果想知道整体前沿，最需要的是综合类期刊，全文的数据量我的笔记本也跑不了，就考虑摘要，这样也过滤了那些没有摘要的评论与观点，更多关注研究性论文。期刊选择为综合类的《科学》、《自然》与《美国科学院院刊》，收集2016年一整年的论文摘要，用&lt;code&gt;easyPubmed&lt;/code&gt;包来搜索并整理成相对干净的数据集。这里我只收集了题目、摘要、出版期刊与日期进行文本数据挖掘。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8,815 x 6
##                                                                          title
##                                                                          &amp;lt;chr&amp;gt;
##  1 A high-throughput small molecule screen identifies synergism between DNA me
##  2                       2017 sneak peek: What the new year holds for science.
##  3                            Wolf transplant could reset iconic island study.
##  4 Scientists in Germany, Peru and Taiwan to lose access to Elsevier journals.
##  5                                                   How scientists use Slack.
##  6                 Saliva protein biomarkers and oral squamous cell carcinoma.
##  7 Reply to Galvão-Moreira and da Cruz: Saliva biomarkers to complement the vi
##  8         Cell morphology drives spatial patterning in microbial communities.
##  9                 Deborah S. Jin 1968-2016: Trailblazer of ultracold science.
## 10 Autophagy wins the 2016 Nobel Prize in Physiology or Medicine: Breakthrough
## # ... with 8,805 more rows, and 5 more variables: abstract &amp;lt;chr&amp;gt;,
## #   year &amp;lt;chr&amp;gt;, month &amp;lt;chr&amp;gt;, day &amp;lt;chr&amp;gt;, jabbrv &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;发文量&lt;/h2&gt;
&lt;p&gt;首先我们先看看着三份期刊的发文量：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../cn/2017-06-16-nlp_files/figure-html/sum-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;这三份期刊里，PNAS发文量最大，占总数一半。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;高频词&lt;/h2&gt;
&lt;p&gt;然后我们看一下各期刊的前十大摘要高频词：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../cn/2017-06-16-nlp_files/figure-html/abs-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;这里解释一下，如果我们单纯寻找高频词其实这几个期刊都应该差不多，但这里我们用的是TF-IDF来加权筛选，这个加权不严谨的说就是这个词出现在该期刊的词频与出现在所有期刊词频的比例，通过这个值我们可以找到单个期刊比较重要的词。我们可以看到肿瘤与行为均出现在三个期刊的十大关键词中，推测相关研究应该是去年的重点。此外，《自然》与《美国科学院院刊》都出现了模型这个词。就特色而言，《自然》去年更关注造血过程、信号传递与衰老问题；《科学》杂志则关心磷酸化、spo11蛋白与火山口还有小尺度问题；《美国科学院院刊》主题特色不算明显，但比较喜欢强调研究重要性。&lt;/p&gt;
&lt;p&gt;如果我们只考虑题目里的文字呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../cn/2017-06-16-nlp_files/figure-html/title-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;这里我们可以看出，《自然》上的论文题目跟摘要内容契合度比较高；《科学》上论文题目喜欢出现中美的国家标签；《美国科学院院刊》看意思题目里专业名词比较多。此外，三份期刊的题目里都出现了勘误，这倒是前沿高影响力期刊的特点：容易被质疑。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;词关系&lt;/h2&gt;
&lt;p&gt;看完整体你应该想到，单个词并非孤立，那么这些词之间会不会有相关性呢？这个问题我们也可以用NLP工具来研究：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../cn/2017-06-16-nlp_files/figure-html/termrelation-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;../cn/2017-06-16-nlp_files/figure-html/termrelation-2.png&#34; width=&#34;672&#34; /&gt; 其实这个技术更常见，平时你用的输入法就实现去考察一些字词的关系，然后让其出现的排序更符合常识。这里我们可以看到，从题目里我们能看到气候变化、干细胞以及前面提到的勘误问题。从摘要里我们则会发现大多数是生物相关的主题，也就是前沿科研应该是生命科学在导向。但到目前为止我们都是把这一些文本当成一个整体，但科学是分科的，也就是有不同的主题，此时我们就要用到主题模型来探索去年前沿科研关注的主题分类。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;主题模型分类&lt;/h2&gt;
&lt;p&gt;所谓主题模型，就是通过探索字词间内部关系对文本进行分类的模型，举例来说某个潜在的主题包含7个关键词，如果某篇文章命中6个，那么这篇文章大概率就属于这个潜在主题。当然，现实生活我们并不知道这些潜在主题会是什么，但通过隐含狄利克雷分布，也就是LDA方法我们就可以去探索结构，然后去拟合实际经验。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../cn/2017-06-16-nlp_files/figure-html/topic-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;从上面我们可以看出，有些探索出来的主题大概我们知道是哪个领域的，有些则属于误判或者说界限不明显的综合领域，这说明跨学科研究正在崛起。其中，我能识别出来的主题大体有癌症、脑科学、病毒、社会行为、基因组、膜蛋白结构、气候变化、进化、动态系统、材料。总体来看，细胞生物学与分子生物学还是主流，但病毒、气候变化等问题导向的学科也在发展。其实也可以直接分析10年的时间变化趋势，不过这个就留成课后题吧（其实是我个人电脑跑不动）。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;情感分析&lt;/h2&gt;
&lt;p&gt;一般认为科研人员都是比较乐观的，但其实文字背后究竟是否乐观可以用文本的情感分析来回答。这个分析的原理就是事先找个标注过情感的语料库，然后通过语料库与词频来分析具体文本的情感倾向性。正常这个语料库是要自己根据语境去构建的，例如商品的好评差评，但作为资深懒汉，我直接用了现成的AFINN语料库：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../cn/2017-06-16-nlp_files/figure-html/sen-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;结果基本符合乐观为主的预期，不过按说有些词在科研中属于中性词，我们可以通过这个分析来考虑论文写作的用词方法。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;其他&lt;/h2&gt;
&lt;p&gt;其实这只是一个很初步的分析，我甚至没用用到引用与被引用的关系，也没有考虑作者与研究机构的时空分布特征，但类似这样的文本分析应该是一个现代科研人员所具备的属性。这种分析的好处在于你不是在采样，而是直接分析所拥有的整体，也就几十兆的文本量，如果你电脑跑得动，把十年二十年的文献沿革都可以概览一下，这是这个时代给我们的红利，不要白不要。&lt;/p&gt;
&lt;p&gt;你可以研究一个大牛几十年的论文发表来发现其独到的眼光；也可以针对某个期刊挖掘其关注点的变更；还可以构建自己认可的课题组的文献库，通过其发表内容探索同行那些自己都没意识到的行为改变。这个时代学科内的经验贬值飞速，很多东西没必要闭门造车慢慢悟，利用开放数据的便利性你可以很快了解整体学术动态，这样不至于随波逐流。更麻烦的是如果你不懂而别人懂，那你将很容易体会到别人眼神中的怜悯，做一个好奇心使然的科研人员，现在起步从来都不晚。&lt;/p&gt;
&lt;p&gt;更重要的是，这类技术本质是让你满足好奇心的，你可以用这个来了解社会，例如纽约时报就给个人提供API，你可以看看其对川普用词风格的变化；为什么最近比特币搜索指数集中在拉美？欧洲吸引难民究竟是政治正确还是劳动力人口不足？不要等着看新闻来指导自己，要学会发现生活中的闪光点；不要通过键盘上情感喧嚣来面对社会，要用键盘甚至语音编程（我果然很自然的想到了最懒的方法）从繁复的公开数据中挖掘趋势；不要总是等着大牛来带，在未知的领域人人都可能成为大牛，你需要掌握一些实现方法而已，你甚至不需要太了解算法细节（会忘，比如我），但要有自己的兵器库随想随用。你不需要带着目的性去学，这说到底只是一种生活方式，你变强了也秃了的可能性是存在的（你能否感到我最近在看漫画）。&lt;/p&gt;
&lt;p&gt;本文实现代码可见我的&lt;a href=&#34;https://github.com/yufree/yufree.cn/blob/master/content/cn/2017-06-16-nlp.Rmd&#34;&gt;Github&lt;/a&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;想要了解世界吗？想要的话可以全部給你，去找吧！我把所有的线索都放在互联网上了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;参考文献&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://tidytextmining.com/&#34; class=&#34;uri&#34;&gt;http://tidytextmining.com/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>留学生、隔离与适应</title>
      <link>/cn/2017/05/22/study-aboard/</link>
      <pubDate>Mon, 22 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/05/22/study-aboard/</guid>
      <description>&lt;div class=&#34;section level1&#34;&gt;
&lt;h1&gt;留学生&lt;/h1&gt;
&lt;p&gt;作为国产土鳖，在海外做博后接触最多的除了土著就是华人移民、各国留学生与国内访问学者，这里面还是有很多有意思的现象，而这些现象其实对应了几篇非常有意思的论文。&lt;/p&gt;
&lt;p&gt;首先我们看一下国内来的留学生群体。目前国内的留学越来越低龄化，很多接触到的国内来的本科生，往往在国内读个一年高中就跑来这边读高中，用这边高中学历来申请学校。大学读完了基本都是身份导向，学签转工签，工签转枫叶卡，枫叶卡转公民。你如果问为什么不回国，他们的回答往往不是常见的国内机会不好，而是认为国内没有认识的人，主流社交关系都在国外，一回国跟回炉重造差不多。这是个死循环，出国年龄越小，人际关系越在海外，越不可能回国。而且很多本科生的高中同学其实在国内也是高中同学，有个留学生跟我说他们国内一个高中班，到了高二整建制的来了北美，这种情况怕是一个也回不去了。&lt;/p&gt;
&lt;p&gt;另一个有意思的现象是留学生中还存在鄙视链。高中过来的鄙视大学过来的，大学过来的觉得研究生过来的太多国内习气不合群，而他们又都鄙视国内交流项目过来的，认为交流生都是拿国家钱混经历，选的课还简单，语言也不行。同样的鄙视链在华人移民中也存在，最早的移民多是劳工移民，八九十年代流行技术移民，前十年是投资移民，最近是留学移民，鄙视链基本就是按照出国早晚与学历来的。国外生活处处需要职业代理人，找华人并不见得比找老外有经济优势，但年龄约长，越喜欢找固定的华人代理人，其实老外也一样。我跟一个刚办移民的博后聊天，他海外博士曾在国内工作过一年，但终究还是觉得国内环境不适应跑出来了，他目前就打算拿身份了而且也坦然说不希望国内发展太好，因为这样就会说明自己选择国外身份是错误的，他希望国内能发展到过的很舒适但比国外还差一点点的状态。这个想法大概在留学生跟移民的内心里都有点吧，不信你去mitbbs上转转就知道了，我倒觉得这个现象其实背后有博弈论的影子。&lt;/p&gt;
&lt;p&gt;还有一个现象是留学生置产。这是个经济问题，很多学生来读书到银行开户问的第一件事就是房价，一般来说，本科来了买房，交了首付把不住的房间出租，租金可以抵消月供，等毕业要回国或外地工作时转卖，读书的时间房价的上涨其实还能赚一笔作为工作启动资金。也许你觉得首付存在外汇管制比较难，我只能说私下的外汇交流挺多的，存在庞大的代理人市场，要不然比特币也不会中国人玩的多，此外国外有定居亲戚朋友需要国内置产的两方利益交换就可以了，当然这个比较吃信任，所以只能亲戚朋友。有位银行职员曾跟我吐槽中国人怎么那么有钱，经常全款买房，买的车也都是好车，一身加拿大鹅，我赶忙解释那些人国内也是有钱人，不代表平均水平，另外奢侈品国内定价比国外高一大截，他们买是因为便宜。&lt;/p&gt;
&lt;p&gt;再就是家长陪读现象。有次跟访学博后聚餐，很意外发现带孩子来的孩子都是学校本科生，说白了很多访学博后出国一方面是学术交流，另一方面也算是陪读。另外陪读家长一般都是母亲，有当地华人说美国西海岸是小三村，加拿大东部则可看作正房陪读村，至于一家之主大都身居国内经商赚钱。不得不说还是国人精打细算，懂得规划自己，处处“精致”。&lt;/p&gt;
&lt;p&gt;然后我们再看下另一个群体，港台留学生或移民，一个特别的现象就是这两拨人互相独立，就连华人学生会也是两个，显著区别就是语言，港台留学生英语更好，私下用粤语。据说97年左右大量香港人移民加拿大，后来又回去一拨，但这也造就了这个群体的人口基础。不过我遇到的港台人都是比较友善的，基本默认不聊政治，也听说过有台湾留学生打飞的回去投票展示优越性，不过台式民主也算是一道别样风景了。&lt;/p&gt;
&lt;p&gt;还有三个我们的近邻留学群体，一个是韩国人群体，一个是日本人群体，另一个就是印巴人群体。韩国人群体跟中国人比较像，勤奋好学，比较鲜明的特点就是韩国人专属教堂，感觉他们的传教士也算是一道风景了。日本人群体则很难发现，因为他们国际留学生读学位的非常少，一方面是因为本国好学校不少，另一方面半终身雇用的日式企业对大三学生要搞什么内定实习，你要跑国外了，回去根本找不到工作，也就是海归在日本并不吃香。但也有例外，那就是如果你去语言学校溜达，会突然发现扎堆的日本人，打听下才知道日本留学主体大都是学语言的，为了企业国际化，语言学校没有学位但有语言环境，时间也就几个月，而且女生比例奇高。这一方面说明日本人留学其实为了国内就业，另一方面，出来读的也大都是不喜欢日式大男子主义的女生，这个现象我们后面分析。至于印巴人，虽然英语带口音，但真的很主动去交流，抱团现象明显，家庭观念强。其比较特色的就是留学生之间相互认识，互相扶持，确实存在移民一个人，带来一大家的现象，而且普遍没有任何归国意愿。&lt;/p&gt;
&lt;p&gt;再有就是中东、南美与东欧留学生群体。这三个群体不知为何经常系统性被忽略，其实也都各具特色。中东留学生大都是来自伊朗，也是勤奋好学，应该说伊朗是个被制裁太多的地方，好好的从世俗国家搞成宗教国家了。但在那个人口基数上人才数量很庞大，灯塔国不欢迎他们，就跑枫叶国了。另外就是我见过的都很能说，滔滔不绝，喜欢打听事，这种八卦文化在中东据说比较普遍。南美留学生也属于比较抱团的，但模式是巴西人单独抱团，其他人抱团，估计也属于语言隔离。南美上世纪陷入中等收入陷阱，到今天感觉还没缓过来，但新兴领域的科研势头也很猛。跟南美人打交道要注意其宗教信仰与家庭结构，一般男士比较健谈活泼，但当家的其实是女士，组里的巴西小哥为了给女友买香水也吃了一个月的简餐。南美人相比中国人更熟悉日本人，可能是南美有数量不小的日本移民，跟他们聊日本动漫会发现也基本就是《七龙珠》跟《足球小子》，对了南美人周末会踢足球，他们主要社交就是足球与健身。东欧留学生跟我们思考方式也比较像，可能是冷战造就的，人口中波兰人非常多，语言上英文都挺好，有机会要去尝试波兰水饺，学术上对数学非常自信，也比较勤奋。&lt;/p&gt;
&lt;p&gt;除了上面这些，还有比较小众的西欧留学生跟东南亚留学生，接触很少，非洲留学生在国内天天见，这边并不多。最后就是加拿大当地人，普遍喜欢嘲笑美国人，特别是大选之后，但比较安于现状，对海外留学生存有迷之优越感但又表现的非常尊重你且尊重规则与多元文化，有时候让人哭笑不得。他们比较喜欢跟人打交道的专业，所以理工科基本是留学生天下，有自己的圈子，留学生基本进不去，但CBC就可以，主要是关注话题不同，脸书跟推特是他们第二家园，给我感觉就是单纯、理想主义但内里是有点排外的并且不太愿意主动了解世界其他“落后”地方。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level1&#34;&gt;
&lt;h1&gt;隔离&lt;/h1&gt;
&lt;p&gt;好了，扯了那么多的现象，现在说点理论。我现在感觉国内外最大的不同就在于国内其实是一元文化而国外存在更多的多元化，这个差别很可能是很多问题的根源。我们用日本来举例，日本就是单一民族国家，当其做学生时，也是大量派出留学生到海外学习，但当其发展起来后，其留学生就更多是实用主义了。中国虽然不是单一民族国家，但基本可以看作单一文化国家，中国人在海外两极分化比较重，要么就彻底认同海外生活，也不打算回来了；要么就根本不认同，在海外构建自己文化圈或就是实用主义，学成归国。但目前来说，留学生中前者比例占优，但如果国家能均衡发展到日本那个程度，后者比例就会提高。而且由于20-30岁的人际关系对事业初期发展很重要，所以出国年龄越早，前者比例会越高，这个也是很多海外优秀人才不想回去的主要原因，担心回去被国内熟人文化玩死。&lt;/p&gt;
&lt;p&gt;国外的多元化则是陌生人文化主导，强调反歧视与文化尊重，更简单的词汇就是政治正确。国内来的人会觉得有时候政治正确会效率低下，例如吃顿饭要先发个调查表问问食物禁忌与是否素食主义；建筑物设计里必须有残疾人车位与通道且经常见到所有车位都满了但残疾人车位还是空着一排；平时聊天需要注意各种雷区…这些跟前面提到的现象有关，一个社会如果是移民社会，那么所有团体都会为自己的文化与习惯争取政治上的尊重，这样的社会就存在单一文化社会里根本就意识不到的不尊重。例如你在沙特可以随意说娶多个老婆但你就是不能说喝酒的事，同样的话放到国内就成了无法理解的论题，而多元社会的人群构成很复杂，所以生活在这样的社会，你会感到所有人对你的尊重，前提是你需要政治争取，如果不争取，还不如单一文化社会，歧视更严重。&lt;/p&gt;
&lt;p&gt;这可能是国内推广女权、LGBT还有其他反歧视最大的难题，如果你生活在多元社会，权利分散而文化多样，大家就可以讨论小团体的问题。但如果这个国家文化惯性比较大，那么这个问题就变成了要么西风压倒东风，要么东风压倒西风，结果很容易把争取权利的一方搞得极端化与妖魔化。不过应该说虽然国家是单一文化的，但城市却可以是多元的，越是大城市与新城市，那些在原有环境不满的多元团体就容易聚集，最终发现自己的局部绿洲。灯塔国就是这么构建出来的，不管前提是原住民几乎死光。而前面提到日本留学生女性为主，很多人其实是不打算回日本，因为那里大男子主义横行，女性事业发展空间有限，此处不留爷，自有留爷处。&lt;/p&gt;
&lt;p&gt;这本质上是隔离问题，所有人都希望生活在最尊重自己的环境中而拒绝不舒服的地方，人又都是两足动物，所以不高兴就用脚投票。最后结果就是大家都在自己认为最适应的圈子里抱团取暖，不关心其他人的生活。这个隔离问题我在之前说过很多次，而且我不认为这是个很好的现象，或者说隔离现象还有一个孪生现象——适应。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level1&#34;&gt;
&lt;h1&gt;适应&lt;/h1&gt;
&lt;p&gt;所有人都是用脚投票，但其实这有个隐含前提，那就是已经做出了选择，观点明确。现实中，这个前提很有问题，多数人是在观察观点而不是发表意见，投票时不见得全心全意。目前我们可以看到两种聚集模式，一种就是按照谢林隔离模型所描述的种族隔离聚集，另一种则是以色列正统犹太人的街区黑化模型，前者我提过很多次不赘述，后者的含义则是当地人转化了外来人的文化，从外来人的角度就是适应了当地的生活方式。所以一个人跑到一个陌生的地方实际上有两种选择：融入或逃离。如果这个人不愿意适应当地文化，那么他就会逃离或者自我隔离；而如果他愿意去适应，就会融入新环境并从内部加入自己文化的组分。&lt;/p&gt;
&lt;p&gt;中国文化其实是很欢迎其他文化融入的，但比较麻烦的是不太欢迎整合其他文化。同样的问题也出现在西方国家，表面上是很欢迎移民但内在却排斥。所不同的是，西方国家存在政治正确的斗争来促进适应的发生而中国文化尊重传统基本是跟政治两条平行线，自由发展。所以适应性问题其实应该当成某种现代人素质进行理解式宣传而不是填鸭式宣传。所有人都不喜欢听别人说自己做错了，但引导他自己得出自己观点需要改进或变化是很有必要的，否则就是单纯情绪宣泄与抱团取暖，并不解决实际问题。&lt;/p&gt;
&lt;p&gt;适应问题其实也不是单一文化国家与多元国家之间的转换问题，搞成多元化却有可能出现“政治正确”而加深隔离现状，而是一个普遍存在尚未解决的问题，古话说就是要达到“和而不同，周而不比”的状态。目前大趋势是表面的文化多元化与内在的认知割裂化，不论国内国外，不论网上网下，不论职业年龄，具体怎么处理，只能说是个个人持续内心斗争决策与对外权益斗争的过程，很难一劳永逸。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level1&#34;&gt;
&lt;h1&gt;参考文献&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;选修c站密歇根大学的模型思考课程，阅读参考教科书&lt;/li&gt;
&lt;li&gt;选修SFI的复杂性科学导论课程，阅读参考论文&lt;/li&gt;
&lt;li&gt;选修c站斯坦福与UBC合开的两门博弈论课程，阅读参考论文&lt;/li&gt;
&lt;li&gt;这是我的相关笔记本：yufree.cn/notes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最近重心转到科研，不会三个主题去写了，比较累。上面的参考文献如果能通读，则会显著提高对社会的了解，就这样。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>组学实验设计中的功效分析</title>
      <link>/cn/2017/05/21/omics-power-analysis/</link>
      <pubDate>Sun, 21 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/05/21/omics-power-analysis/</guid>
      <description>&lt;p&gt;最近设计了一组代谢组学实验，因为用到动物所以需要学校动物保护委员会的许可，完成了一系列理论学习与实验室参观后，主管人员要求提供预实验结果与功效分析来确定动物数量。这个要求就诡异了，组学实验同时测上千个指标，这功效分析根本无从谈起。但因为是必填项，硬着头皮去查了下资料，如果是代谢组学数据，确实基本没人提功效分析，有也是针对特定测量值。然而，蛋白质组学跟基因组学都曾经讨论过这个问题，这里我大体总结下。&lt;/p&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;功效分析&lt;/h2&gt;
&lt;p&gt;常规功效分析至少需要显著性水平、组内标准差、组间差异、功效及检验方式来确定样本数。其实说白了就是知道想看到一个显著差异所需要的最小样本数，如果不能达到这个数，那么你这个实验基本可以当成白干了。功效分析跟显著性分析关注点并不一样，前者关心看到的差异真不真，后者关心这个差异存不存在。一般而言，控制实验都能看到差异，所以关心这个差异靠不靠谱其实对实验设计很重要，而具体表现就是样本数。样本越大越容易看出细微差异，如果样本数固定，那么可以通过功效分析测定哪些差异靠谱。从上面我们可以总结出两点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;功效分析需要显著性水平的设定&lt;/li&gt;
&lt;li&gt;功效分析是知道多个求一个，这个数可以是样本数，也可以是差异本身&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;组学实验&lt;/h2&gt;
&lt;p&gt;组学实验最大问题就是同时测定两组样本的多维属性，这里面显著性水平要考虑整体错误发现率。同时，功效分析对于单一变量考察是没什么问题的，但如果你同时测量多个变量，那么这个样本数对不同变量应该是不一样的。你需要对结果进行筛选，而这个筛选反过来影响样本数。此外，组学实验中存在大量白噪音，不考虑这个问题的功效分析也是有问题的。我们通过下面的例子来说明。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;示例&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BiocParallel)
library(xcms)
## Load 6 of the CDF files from the faahKO
cdf_files &amp;lt;- dir(system.file(&amp;quot;cdf&amp;quot;, package = &amp;quot;faahKO&amp;quot;), recursive = TRUE,
         full.names = TRUE)

## Define the sample grouping.
s_groups &amp;lt;- rep(&amp;quot;KO&amp;quot;, length(cdf_files))
s_groups[grep(cdf_files, pattern = &amp;quot;WT&amp;quot;)] &amp;lt;- &amp;quot;WT&amp;quot;
## Define a data.frame that will be used as phenodata
pheno &amp;lt;- data.frame(sample_name = sub(basename(cdf_files), pattern = &amp;quot;.CDF&amp;quot;,
                      replacement = &amp;quot;&amp;quot;, fixed = TRUE),
            sample_group = s_groups, stringsAsFactors = FALSE)
## Read the data.
raw_data &amp;lt;- readMSData2(cdf_files, pdata = new(&amp;quot;NAnnotatedDataFrame&amp;quot;, pheno))
## Find peaks 
cwp &amp;lt;- CentWaveParam(snthresh = 20, noise = 1000)
xod &amp;lt;- findChromPeaks(raw_data, param = cwp)
## Doing the obiwarp alignment using the default settings.
xod &amp;lt;- adjustRtime(xod, param = ObiwarpParam())
## Define the PeakDensityParam
pdp &amp;lt;- PeakDensityParam(sampleGroups = pData(xod)$sample_group,
            maxFeatures = 300, minFraction = 0.3)
## Group the peaks
xod &amp;lt;- groupChromPeaks(xod, param = pdp)
## Fill in peaks with default settings. Settings can be adjusted by passing
## a FillChromPeaksParam object to the method.
xod &amp;lt;- fillChromPeaks(xod)
## Get the data matrix
data &amp;lt;- featureValues(xod, value = &amp;quot;into&amp;quot;)
## Get the complete cases
data0 &amp;lt;- data[complete.cases(data),]
dim(data0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 243  12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在上面的示例中，两组数据每组样本是6个，共提取出了243个峰的完整数据，那么，此时的功效分析首先要确定整体错误发现率。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(genefilter)
## Get group infomation
lv &amp;lt;- as.factor(pData(xod)[,2])
## Get median difference and standard deviation in one group
tr &amp;lt;- rowttests(data0,lv)
## Estimates the proportion of true null p-values, for FDR
ts &amp;lt;- mean(abs(tr$statistic),na.rm = T)
library(qvalue)
pi0 &amp;lt;- pi0est(tr$p.value)$pi0
hist(tr$p.value,breaks = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../cn/2017-05-21-omics-power-analysis_files/figure-html/FDR-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pi0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从上面我们可以看出这一组多重比较数据的p值分布符合均匀分布, 道理上说这组数据基本可以看作没有多少差异，但直方图却显示应该存在一些有显著差异的峰。那么我们基于当前数据可以进行一下功效分析，看看究竟差异多大可以认为是真的。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Get median difference and standard deviation in one group
dm &amp;lt;- median(abs(tr$dm))
sd &amp;lt;- median(rowSds(data0[,1:6]))
## Get the difference
library(ssize)
## Get the differences number fitting the power in this DoE
power.t.test.FDR(n = 6, sd = sd, FDR.level = 0.05,power = 0.8, pi0= 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##      Two-sample t test power calculation 
## 
##               n = 6
##           delta = 6149021
##              sd = 366486.2
##       FDR.level = 0.05
##           power = 0.8
##     alternative = two.sided
## 
## NOTE: n is number in *each* group&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(tr$dm&amp;gt; 6149021)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Get the sample numbers fitting the power and 50% differences true in this DoE
power.t.test.FDR(delta = dm, sd = sd, FDR.level = 0.05,power = 0.8, pi0= 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##      Two-sample t test power calculation 
## 
##               n = 9675.235
##           delta = 136197.7
##              sd = 366486.2
##       FDR.level = 0.05
##           power = 0.8
##     alternative = two.sided
## 
## NOTE: n is number in *each* group&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样我们大体可以认为，在当前实验设计下，只有1个峰的显著差异是靠谱的。同理，也可以计算出如果想看到50%的差异为真，我们每组需要9675个样本。&lt;/p&gt;
&lt;p&gt;同时，如果不考虑错误发现率的结果则是：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;power.t.test(n = 6, sd = sd, sig.level = 0.05,power = 0.8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##      Two-sample t test power calculation 
## 
##               n = 6
##           delta = 658041.6
##              sd = 366486.2
##       sig.level = 0.05
##           power = 0.8
##     alternative = two.sided
## 
## NOTE: n is number in *each* group&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(tr$dm&amp;gt;497799.2,na.rm = T)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 27&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;power.t.test(delta = dm, sd = sd, sig.level = 0.05,power = 0.8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##      Two-sample t test power calculation 
## 
##               n = 114.6297
##           delta = 136197.7
##              sd = 366486.2
##       sig.level = 0.05
##           power = 0.8
##     alternative = two.sided
## 
## NOTE: n is number in *each* group&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当前实验可以发现27个差异是靠谱的，或者需要每组115个样品才能表示出一半的差异是真的。&lt;/p&gt;
&lt;p&gt;产生上述问题的本质在于高通量数据的错误发现率控制降低了发现差异的p值，所以更少的差异是真的。同时如果严格控制错误发现率，那么所需要的样本数会非常多。此外，这个结果提示我们如果样本数不多，那么你其实只能对那些差异很大的峰给予信心。&lt;/p&gt;
&lt;p&gt;但上面的计算有一个最大的问题，就是组内标准差其实差异很大，此时应考虑每个样本的情况:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;power &amp;lt;- 0.8
alpha &amp;lt;- 0.05
pv &amp;lt;- tr$p.value
df &amp;lt;- cbind.data.frame(tr$dm,rowSds(data0[,1:6]),alpha,pv)
df &amp;lt;- df[df$pv&amp;lt;0.05,]
rs &amp;lt;- vector()
for (i in c(1:nrow(df))){
        r &amp;lt;- power.t.test.FDR(delta = abs(df[,1][i]), sd = df[,2][i], FDR.level = 0.05,power = power, pi0 = 1)
        rs[i] &amp;lt;- r$n
}
sum(rs&amp;lt;6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样，我们发现会有0个差异是真正显著的，这比使用平均样本控制得到的少，说明单个去看其实更难找到真正有差异的峰。&lt;/p&gt;
&lt;p&gt;功效分析不一定会得到跟FDR控制更少的峰，而且FDR控制的算法设计里实际也考虑了类似的过程，但是从全局分析的功效分析对于实验设计非常有用。当你进行了一组预实验，功效分析可以告诉你结论中多少峰是靠谱的，如果一个都没有，那么就增加样本量吧。如果你的研究目的是至少发现一个峰是靠谱的，也就是生物标记物研究，那么此时功效分析所需的样本数最好再多一个，否则结论可能无意义。&lt;/p&gt;
&lt;p&gt;下面就把上述过程整合成一个函数，输入提取好的MSnExp对象与功效值、p值与q值的阈值就可以返回一个满足条件的峰列表，这个函数只对两组数据对比有用，也仅适合 xcms 3 的新对象类型，不过稍微修改就可以推广到其他检验方式了。这个峰列表是进一步研究的基础，如果不严格考察，后面的分析大概率得到错误结论。在检验模型的选择上，如果你的数据存在技术重复或需要线性混合模型求解，这里面的功效分析会比较不同，需要你自己设计算法求解，这里不展开说了，大概是个生统硕士论文的工作量。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(genefilter)
library(qvalue)
library(ssize)
getrealpeaks &amp;lt;- function(xod, power = 0.8, pt = 0.05, qt = 0.05, n = 6){
        data &amp;lt;- featureValues(xod, value = &amp;quot;into&amp;quot;)
        idx &amp;lt;- complete.cases(data)
        data1 &amp;lt;- featureDefinitions(xod)
        mz &amp;lt;- data1$mzmed[idx]
        rt &amp;lt;- data1$rtmed[idx]
        lv &amp;lt;- as.factor(pData(xod)[,2])
        data0 &amp;lt;- data[idx,]
        tr &amp;lt;- rowttests(data0,lv)
        qvalue &amp;lt;- qvalue(tr$p.value)
        pi0 &amp;lt;- qvalue$pi0
        alpha &amp;lt;- pt
        df &amp;lt;- cbind.data.frame(diff = tr$dm,sd = rowSds(data0[,1:n]),p = tr$p.value,qvalue = qvalue$qvalues,mz,rt,data0)
        df &amp;lt;- df[df$p &amp;lt; pt,]
        rs &amp;lt;- vector()
        for (i in c(1:nrow(df))){
                r &amp;lt;- power.t.test.FDR(delta = abs(df[,1][i]), sd = df[,2][i], FDR.level = qt,power = power, pi0 = pi0)
                rs[i] &amp;lt;- r$n
        }
        df &amp;lt;- cbind(n = rs,df)
        df &amp;lt;- df[df$n &amp;lt; n &amp;amp; df$qvalue&amp;lt;qt,]
        return(df)
}
getrealpeaks(xod = xod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] n        diff     sd       p        qvalue   mz       rt      
##  [8] ko15.CDF ko16.CDF ko18.CDF ko19.CDF ko21.CDF ko22.CDF wt15.CDF
## [15] wt16.CDF wt18.CDF wt19.CDF wt21.CDF wt22.CDF
## &amp;lt;0 rows&amp;gt; (or 0-length row.names)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>差异、相似与模式</title>
      <link>/cn/2017/05/17/pattern/</link>
      <pubDate>Wed, 17 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/05/17/pattern/</guid>
      <description>&lt;p&gt;最近审了一份主题是质谱数据分析的稿子，领域是分析化学，很明显的感受就是作者但是很明显是为了用新方法而用，没有从问题出发，所以借机讨论总结下科研数据分析的思考视角。 差异&lt;/p&gt;
&lt;p&gt;科研数据分析最基础的出发点就是寻找差异，你观察到了两组数据，这个分组是根据实验设计或人为划分的，你想了解两组数据差异。最朴素的思路就是分组聚合，例如选取出现最多的众数，排序中间位置的中位数以及平均值。但是这个思路只是简单的将一组数描述为一个数，并无法表示这组数的离散程度，也就是丢失了一部分可以进行对比的信息。如果你考虑上表示离散程度的方差，结果就成了对比两个数。这样的对比其实只是描述性的，如果你愿意且具备统计与数学功底，你可以构建出无数用来描述一组数据的单一或多个数值进行比较，这些数值在不同领域可能有不同称呼，可以理解为指标，或者称作统计量。统计量的构建至少满足两个条件：包含想要考察的信息与具备可比较的数学性质。前者比较好理解，后者就需要概率论做基础了，在必要时可根据实际问题修改统计量的数学描述方式。万万不可别人让你用什么就去用什么，这样永远是雾里看花。&lt;/p&gt;
&lt;p&gt;有了统计量，我们就可以进行比较了。不论你使用p值还是贝叶斯推断，其核心思路就是将统计量对应到一个分布里去，然后从概率视角看一下这个差异离不离谱（或者跟先验的概率分布比较），如果离谱就认为差异是显著的，跟0差异不大就认为没有明显的差异。但需要知道的是没有明显的差异是对应你假设检验方法而言的，不是说真实是没差异的，用不同的检验方式，结果可能不同。对于严谨的科学发现，主流的检验方式得到的结论应该是相似的，如果结果有差异，那么要么是检验方式无效或不适用，要么就是你的数据对差异判断并不支持。很多时候，如果技术发展不到位，数据的噪音掩盖信号，此时你不能验证结论，需要上更先进的仪器。从这个角度看，数据采集技术是否先进会制约科学发现，这也是很多学者寻求发展时经常要考虑平台是否先进的根本原因，没有技术平台，科学发现只能说模棱两可。好比你想用放大镜研究细胞结构，基本只能拿着鸡蛋看看了。&lt;/p&gt;
&lt;p&gt;差异多数时候是两两间的，但有时候我们的问题是在某个因素不同水平的影响是否显著，例如我想知道某种污染物的自由态浓度是否受高中低不同土壤含水量的影响，这里土壤含水量是因素，高中低是三个水平，此时用方差分析就可以得到土壤含水量是否影响污染物自由态浓度的判断。推而广之，如果水平是连续变量，那么此时的差异分析实质上是相关分析或者说是线性模型的一个特例。你总是要对模型系数进行假设检验来确定这个系数是否影响了你要考察的变量，如果你要进一步进行讨论，参考下面的模式那一部分。&lt;/p&gt;
&lt;p&gt;发现一个差异并从统计角度说明其出现概率比较低或跟先验知识包含不同的信息量是科研数据分析最常见的应用场景。基本思考流程可以归纳为首先构建代表性可比较的统计量，然后进行假设检验的比较，最后根据结果给出判断。这个判断过程有统计学与概率论做支撑，独立于观察过程，因此判断具备相对客观的属性。&lt;/p&gt;
&lt;p&gt;相似&lt;/p&gt;
&lt;p&gt;另一个科研中常见的数据分析场景是寻找数据的共性，但其实基本思路跟找差异比较接近但面对的数据结构会不太一样。在差异分析中，通常考察的是单一属性；相似性分析中，通常你会得到对同一客体的多个描述角度。举例而言，我得到两组河水样品，想知道两组水样是否接近，此时每组样品如果只测定一个指标，那么对比一下就完了；但如果测了很多组指标如何来衡量？两组河水pH值很接近但COD差距很大，可同时溶解氧几乎相同，如何判断？&lt;/p&gt;
&lt;p&gt;一个朴素的想法就是测量可比指标间的标准化差异，然后求绝对值和或平方和，越大表示相似度越小，或者用类似核函数的思想把高维数据映射到低维空间，还可以进行傅立叶变换来通过低维数值保留核心信息量进行比较。此外一个我非常欣赏的思路就是通过打乱分组构建随机统计量来对比实际发生的统计量出现概率，大概就是Fisher精确检验的套路，这个角度是纯统计思路且在计算不那么贵时很好用。&lt;/p&gt;
&lt;p&gt;相似性分析的科研应用场景会越来越多的，首先是数据库比对，目前组学技术发展很快，相关数据库累积也很快，你发现一个功能蛋白，反推出序列可以直接去搜库做进化树，这里面的相似性分析大都用到的动态编程与数据变换，不然速度跟不上。在质谱上就是谱库检索与比对，此时要考虑同位素分布、质量亏损、源内反应加合物等等，不然也很难比对相似性。另一个应用场景是非监督学习里的聚类分析，这里面相似性统计量是进行聚类的基础。其实虽然科学发现里寻找差异更符合探索逻辑，但实际上当前的数据驱动性研究更多是发现共性，当数据累积越来越多，对于共性的新研究方法或新统计量的提出可能更有价值。&lt;/p&gt;
&lt;p&gt;模式&lt;/p&gt;
&lt;p&gt;差异与共性分析都是最基础直观的科研数据分析思路，学科内规律性的东西有时候并不能直接从差异跟共性分析中得到，这时需要识别数据中的模式规律。所谓模式在科研结果中有两种，一种是探索未知，另一种是拟合已知。前者并不需要特别强的理论基础，用来发现模式；后者需要有比较强的理论支撑。&lt;/p&gt;
&lt;p&gt;拟合已知的最常见，例如线性拟合、多项式拟合等，很多时候由本学科的理论来提供基本形式，例如物理里的牛顿三定律、化学里的能斯特方程、生物里的米氏方程。这些方程的数学形式已经在学科内得到了认可，所以当你获取相关数据时，模式是固定的，你所需要求解的是某个参数。参数的稳定性也可以侧面反应理论的真实性，但拟合严格说更像是验证模式而不是发现模式。同时拟合背后的理论基础及来源也是要深入理解的，例如做吸附等温线有两种基本拟合方式：弗里德里希方程与朗缪尔方程，如果你搞不清机理随便用任何一种都会发现拟合效果都说得过去，但一个是纯理论另一个是经验公式，在使用时得考虑你研究目的。有一类研究比较看重预测效果，此时拟合就可以放宽，例如用多项式拟合考虑个自由度就可以了，甚至有时候可以考虑不同数值范围采用不同数学形式，在边界上用样条平滑下就可以了。但不论拟合理论公式还是经验公式，起码这类分析总还是有个数学公式来做骨架的，探索分析则没有这个限制。&lt;/p&gt;
&lt;p&gt;探索未知模式并不是说让你直接把所有科学问题都抽象成 y = f(x) ，然后你收集一大堆y跟相关x，直接扔到多层人工神经网络里去训练，然后搞个验证集看下效果就用，这是工程学思路，到头来也许解决问题，但你可能根本不理解问题。正常的探索过程基本还是有个模型指导的，你可以从最简单的线性模型开始尝试，然后不断提高模型的复杂度，例如引入交互作用或不同x用不同模型的广义加性模型。当然，你可以引入层级模型来探索数据内部结构。当模型复杂到一定程度，就有点人工神经网络的意思了。如果你是为了发现新模式，那么可视化手段是很好的探索起点。但如果是为了预测，其实样条平滑、小波分析等黑魔法就可以随意发挥了，大前提是你真的理解算法，知道自己在干什么。&lt;/p&gt;
&lt;p&gt;从寻找差异开始，我们很多朴素的想法背后其实都有基本模型在起作用，例如t检验就是方差分析的特例、方差分析就是线性模型的特例，线性模式又可以推广到广义线性模型。从最原始的单一统计量构建到多个独立统计量关系探索，再到考虑交互作用，再到层级结构，模型的复杂度可以不断提升。模型的生成过程也要伴随大量的验证与理论支持，并不是随意可以套用，除非你搞机器学习。其实你应该体会到数据分析与科学发展是紧密联系而不是割裂的，很多数据分析方法就是为解决特定科学问题提出来的，没有想象的那么黑箱，反倒是总把新数据分析方法当成黑箱的思路是很危险的。在绝大多数情况下，科学问题的数据分析方法都是针对性的，你也应该能从分析过程体会到背后的抽象与基本假设，否则并不真正理解，虽然这可能不妨碍你发文章。&lt;/p&gt;
&lt;p&gt;从问题视角出发去构建一个方法要比直接套用学科内常见方法更容易体会到《科学研究的艺术》。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>社会感知、文献解读与棋盘思考</title>
      <link>/cn/2017/05/06/social-sense/</link>
      <pubDate>Sat, 06 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/05/06/social-sense/</guid>
      <description>&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;社会感知&lt;/h2&gt;
&lt;p&gt;最近看到一篇&lt;a href=&#34;http://journals.lww.com/co-allergy/Fulltext/2017/04000/Social_media_use_for_occupational_lung_disease.4.aspx&#34;&gt;综述&lt;/a&gt;，大意介绍了下通过社交网络数据来进行职业性肺病的研究趋势。其实回想一下，从大概四五年前就开始有利用类似数据进行研究的报导了，甚至还有个相关名词：社会感知。&lt;/p&gt;
&lt;p&gt;字面理解，社会感知通过收集社会群体传感数据来研究社会中群体行为或相关科学问题。例如，我收集医院呼吸科就诊数据，然后看看这一观察点是否与其他环境因素或个体遗传因素有关联，譬如有人会&lt;a href=&#34;http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0153099&#34;&gt;发现&lt;/a&gt;雾霾严重时呼吸科就诊率会上升。但其实研究可以不局限于特定行业，社交网络的快速发展一方面成为很多人日常生活的必需品，另一方面也提供了大量信息输出。例如有人就&lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2835988&#34;&gt;研究&lt;/a&gt;过在重度空气污染时人们会在微博上的讨论行为。同样的主题似乎在地理学研究中用到，我曾听过一个报告使用的就是微博签到数据来观察旅游旺季游客的聚集行为。如果不局限在国内，实际各大不存在的社交网站都发表过类似论文，有的是基于地理信息，有的是基于语义分析，还有的则基于传播结构用图论的方法去研究。&lt;/p&gt;
&lt;p&gt;总的来说，社会感知可以看作一个研究手段或视角，其应用面还可以更大。就环境分析而言，污染物调查类论文往往侧重于研究其在环境介质中的迁移转化规律，但逻辑上看，污染物的产生多半是人类行为，也就是说迁移转化规律也可能从社会感知角度去考察。例如我们可以关注一些污染企业的经济指标，其波动很有可能与污染物的环境浓度产生关联，如果是滞后性关联，我们是可以预测一些污染的集中爆发的。同样，人们在社交网络里关注的污染物是存在新闻传播高峰的，也就是脉冲式的，但污染物浓度的变化一般是连续的，这之间的差异或趋势可以用来区别环境污染的生理影响与心理影响。如果环境科研工作者不尽快掌握相关研究手段，那么不出意外做社会学研究或计算机科学研究的人会渗透过来。&lt;/p&gt;
&lt;p&gt;最近掌握相关数据的公司纷纷成立研究院，人员组成学科背景都比较多样，很有可能比学术界优先发现有意思的现象。相比之下，学术界学科间壁垒还比较明显，很有可能因为研究手段的落后而走下坡路，而且业界科研的待遇在国外是普遍高于起步期学界待遇的，而人才的流动一般都会是往前沿去，如果在业界那就会流向业界。现在的研究视角越来越多样化与面向问题出发，单一学科或视角、固定的研究模版与闭塞的交流很容易快速衰落而不自知。例如当前大家都喜欢投学科顶尖期刊，很多老牌期刊却存在门户之见，对新方向把握不充分，新研究无法在原有学科体系内成长就会到其他领域或开辟领域野蛮生长，很多人看不上眼的 plos one 跟 scientific report 等新综合性期刊在慢慢孕育新学科。从引用量上可能不明显，但媒体曝光度上来说，新的研究方向更高。如果所有科研经费总量不变，新学科趋势通过媒体影响力会去逐渐挤占传统学科的资源，届时可能会出现系统性学科衰落。这就好比科学共同体的新陈代谢，缓慢却不可逆。所有学科都曾是新学科，也将会成为传统学科，如果内部不能换血，那就只能等外部输血了。这里血指的就是类似社会感知这样的前沿趋势与视角，这对起步期科研人员尤其重要，因为一旦搞错形势，后面不论你多努力可能都会有一种听天由命的焦虑感。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;文献解读&lt;/h2&gt;
&lt;p&gt;最近几年，科普类网站或公众号的快速崛起促进了科学传播，越来越多的人愿意去把最前沿的研究发现带给有好奇心的听众，特别是目前正在进行科研工作的研究生与老师。但我发现很多人在进行解读时并没有很好的说明白研究类型而更多去讨论发现的事实与意义，这样会形成一些误解。&lt;/p&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;没有研究基线的盲信&lt;/h3&gt;
&lt;p&gt;很少有研究是凭空蹦出来的，但对科学报道的受众而言，绝大多数都是头一回听到一些研究领域。也就是说听众都是白纸一张，你说什么他们会首先接纳为事实而不是批判思考，因为多半根本就没有提供批判思考的知识体系。所以文献解读很重要的一点就是要说明我们之前对这个问题了解到什么程度了，有一个基线与背景可以让读者去展开批判思考而不是全盘接受。由于很多论文解读出自领域内专家，而专家通常喜欢用复杂术语树立权威感，所以这个偏误多半只能读者自己揣度，留有余地。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;现象与规律分不清&lt;/h3&gt;
&lt;p&gt;社会科学方面的研究论文解读时经常出现，论文描述的是当前现象，但解读时进行了规律演绎。例如队列研究发现富人们存在早期打高尔夫球的共同喜好，这是一个现象，不能解读成当前你去打高尔夫球，以后就可能变成富人。现象与规律分不清不能用简单的相关不代表因果来解释，更深层次的问题在于，即便很多现象说明的因果关系是事实存在的，时过境迁后，这个因果关系解除了。同样是上面的例子，也许早期打高尔夫球其实是因为能在高尔夫球场获取更好的人脉，但如果现在富人们主要社交方式变成打壁球，那么这个现象只能描述为历史事件，曾经是合理的，但当前完全不合理了。规律是相对稳定不变的而现象是历史性的，一般读者看论文解读的视角是规律视角而不是现象视角，如果解读者自己没搞清楚，那就很容易产生误导。多数科学发现都是有语境的，语境就是适用范围，也可理解为历史条件下的现象。而放之四海而皆准的规律是可遇不可求的，特别社会科学里存在舆论反馈与行为习惯的转变，很多结论在自然态下成立在社会系统中就面目全非了，整个社会到处都是局部最优解与区域护城河，不能当成均相系统研究。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level3&#34;&gt;
&lt;h3&gt;决策风险&lt;/h3&gt;
&lt;p&gt;要知道很多人的决策，特别在健康、育儿与理财等切身相关的主题决策上是很依赖专家意见的，一旦误导后果都是自负的。烟盒上都标个吸烟有害健康，论文解读上最好也提升下决策风险。不知道从什么时候开始，很多原来自然而然的事都出现了各种专业人士去提供服务并帮助决策，所有人都变成了决策困难者。就育儿而言，当前最新的研究成果与30年前父母自己摸索的育儿经验究竟能造成多大的差异，我想这也是个摸石头过河的事。但解读研究成果的人往往并不提示风险，直接论述方法与成效。从读者角度，这个风险往往会被期刊的权威性所掩饰，但事实上越是影响力大的期刊，撤稿率越高；越是前沿的发现，越有可能是缺少证据的。如果论文解读最终变成了个人经验的论述，那么读者应该放弃其决策价值，不然跟信教没啥区别。&lt;/p&gt;
&lt;p&gt;关于文献解读甚至其他种类的文章，读的时候最好也要有点类似社会感知的想法，想想看这是不是现象唯一的解释与思考视角？解读者有没有夹藏私货？自己有没有意识到其中的偏误与决策风险？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;棋盘思考&lt;/h2&gt;
&lt;p&gt;上面关于文献解读的分析实际上也只是棋盘思考的一个应用。设想你跟我下棋，如果你下你的，我下我的那就没意思了，一般情况双方都会去思考对方的立场与策略。好比你去考试，如果你身经百战，那么你一定掌握了出题人视角与阅卷人视角，出题人考察你对某个问题的理解而阅卷人关注的是得分点，作为答题者最好就是把答案分条，展示你理解了某个知识点。其实出题人与阅卷人也会意识到答题者的应对策略去制定答案，这样最后真正懂问题的人总会高分通过，而一知半解的人很难蒙混过关。而在互联网上看信息或报道，你至少要意识到一个三方对弈场景。&lt;/p&gt;
&lt;p&gt;所有报道都存在一个事实基础，把事实展示给你的人是第二方，第三方就是你。大多数人并不能意识到事实与展示事实的人之间的互动关系而看成一体，但其实立场差异不同。A采访了B，B所叙述的事实经过A的加工往往会产生微妙的情感共鸣与调动，而受众就是C。C永远只看到A笔下的B，甚至B是否存在C都不会去怀疑。C当然可以自主采访B，但同样C在描述时也是带有某些情感共鸣的。想到这一点，所有报道，包括自己所提供的，对于别人都是相对主观的。也就是说，棋盘思考的核心不在于了解对方想的是什么，而是意识到自己的局限性。&lt;/p&gt;
&lt;p&gt;只有知道自己的局限性，才能对别人的局限性进行合理评估并达成一定程度上的信任或不信任。这始终都是个决策问题，只是日常生活中发生的太过频繁，很多人意识不到其中发生的过程，总是跟着感觉走。但其实跟着感觉走可能也是一种良好的决策，只是在行为经济学大行其道的今天，总有商人盯着你的行为，考虑能否从中挖到一桶金。无论如何，现代社会实在是错综复杂，所有人都在犯错或试错，站在承认局限性的位置思考总不会错的太离谱。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>环境化学的组队原则</title>
      <link>/cn/2017/04/21/es-team/</link>
      <pubDate>Fri, 21 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/04/21/es-team/</guid>
      <description>&lt;p&gt;最近同组两个博后都拿到了教职，聊天时就说到了自己建课题组所需要的人员组成。因为当前课题组的研究方向是分析化学，所以一般至少会需要仪器仿真方向、材料合成方向、数据处理方向与特定应用方向的人才。如果是课题组长，这四方面至少要会两到三项，不然很多项目根本做不起来。回过头来想想，环境化学其实也可以考虑下组队问题。&lt;/p&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;平台&lt;/h2&gt;
&lt;p&gt;环境化学目标污染物常规一点的大概就是无机方面的重金属与有机方面的农残、食品添加剂、POPs名单上那一坨、PPCPs还有一些生物毒素。往前沿看基本都是非目的检测或筛选，简单一点的是已知污染物的代谢产物与结构类似物，复杂一点就是效应诱导分析或通过QSPR预测毒性这类。这些主题比较热门，如果是环境调查方向，可以各种污染物排列组合去发，毕竟考虑三间分布的话，时间地点人群不同，迁移转化规律也不一样。同时还有非生物介质、生物介质等等污染物载体的差异，研究视角不同，看到的东西也不一样。&lt;/p&gt;
&lt;p&gt;从分析技术上看，首先得有前处理设备。常规的超声、ASE、SPE、旋蒸、氮吹、离心机等得有，如果是作方法学的，什么SPME、整体柱、分子印迹、微流控、离子液体、纳米颗粒负载修饰等技术得有会的人，特别纳米材料那一块，考虑上磁性容易做出体系，当然实用性另当别论。这些设备与技术能让你萃取净化到目标物，当然你做无机搞微波消解然后赶酸啥的当我没说，你们那不叫前处理。&lt;/p&gt;
&lt;p&gt;处理完了的东西就要检测，环境分析检出限都是ppb级及以下，有机的就别来掺和了。无机检测ICP-MS是一站式解决方案，你要有钱搞得起MC-ICP-MS还可以做无机同位素分析，前提是有钱。有机一般就是质谱了，获取你比较关心核磁红外紫外，但那个出的结果大概率被审稿人鄙视。不过核磁另当别论，关键环境污染物含量太低，一般满足不了核磁要求，如果你能找到做合成的人帮你鉴定未知物那最好不过。质谱里面有条件上obitrap就上，再不济也得有个tof，如果你有FT，那基本可以抛弃前面的色谱了。定量的话qqq跟单杆最好都有，离子阱如果不做便携质谱或是普渡厨子的门生就不要考虑了。电离源也要配齐，气谱EI跟CI，液谱ESI跟APCI，冷门点的双喷雾或DESI也可以搞搞，不然有些污染物你可能根本就测不到。光谱也是一个思路，不过你得往高通量或可视检测去做，发不出文章也可以出点专利产品，这部分一般思路就是做抗体或者化学发光、荧光啥的，主要就是原子分子光谱，不过跟质谱比最大的优势可能就是便宜了。此外，表面共振拉曼光谱也是个快速发文章的渠道，配合一些稀奇古怪的修饰，总能在现场分析上找到突破口。光谱其实也有个大杀器，光源，前提你约的上，高能射线下能对很多过程进行细致分析与成像。此外，元素分析、各类显微镜电镜还有生物方向的特异性分析、测序跟芯片技术在环境领域也有应用，就看你想回答的科学问题是什么了。&lt;/p&gt;
&lt;p&gt;上面扯半天主要就是说得有个仪器平台可以依赖，而且多半你也不会买维修合同，这说明初期得有点当金工、电工甚至木工的手艺，没有也没关系，好的平台一般都标配。我现在组里那几台质谱基本都是老板各种谈判低价搞过来的，不是二手demo机就是根本已经坏了，故障五花八门全是自己修，搞得这边博士生毕业都可以去培训仪器公司工程师了，反正多数上门工程师的顶级秘籍就是换件。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;人才&lt;/h2&gt;
&lt;p&gt;仪器只会报数，只有人才能把数据变成论文。在这一点上，一个课题组至少要有一个人有数理统计与编程技术背景，甚至每个组员都要有应用层次的编程技术。这可不是说看到别人用了pca，你也用pca去照猫画虎，你至少要知道这些技术为什么用，什么时候用，怎么用。只有这样写论文时才知道你在干什么而不是只知道套模版怎么做。软件工具python、r或matlab都可以。此外，也要有一个工科背景的员工或博后，懂仿真。统计模型与仿真模型完全是两个概念，一个面对数据归纳，一个面对实物或系统用规律演绎；一个用回归，一个各种偏微分方程；一个做假设检验，一个直接在虚拟空间进行实验。小到模拟一个吸附解吸过程，大到生态系统的物质能量循环，仿真模型与统计模型是要相辅相成的。软件工具comsol、matlab甚至netlogo都可以。这两类人是基础人才，能把数据变成故事。&lt;/p&gt;
&lt;p&gt;但作为独立课题组只有基础人才是不够的，课题组长一般都有一技之长。环境化学最容易耦合的学科是毒理学、污染控制与环境暴露。毒理学上的人才要对污染物致毒的分子机制玩的转，懂得基因修饰去验证被污染物影响的生物学过程，当然偷懒一点搞点QSPR研究下分子蛋白相互作用机制也是可以的，不过你得真的搞得明白从分子动力学到DFT那一系列的坑，你搞不明白没关系，別坑学生。当然，现代毒理学里急性慢性毒性实验、行为学表征还有流式细胞术什么的基本每篇文章都是标配，不是你的长处也别成为短处。更深入的组学技术如果不是基础够强，花钱找公司做，但数据分析要自己来，很多公司的数据处理技术还停在上个世纪。如果你是污染控制方向，污染物的降解热力学动力学自然要了解吧，拿个mopac算算前线轨道能也可以编出个不错的故事。如果你跑去做工艺养污泥颗粒，那目前似乎没点基因芯片也说不清楚降解机理了。如果你是大气环境化学方向，额，你似乎兼顾有点催化背景好一点。如果是土壤，怎么说也淋过土柱玩过同位素标记吧。如果你搞了个环境暴露方向，最好认识医院里那些缺论文升职称的大夫，随便搞点病人与健康人的样品测下污染物浓度就可能有不错的发现。如果你是公卫那边转过来的，搞点暴露组学配合流行病学研究会有不错的故事。如果你气象那边过来的，搞点气候变化对污染物迁移转化规律的影响也会不错。总之课题组长要会找到研究切入点与生态位，跟风怎么也要等你手头有资源再说，早期做出特色更重要。&lt;/p&gt;
&lt;p&gt;说了这么多你会发现现在要想做出点名堂多半是要靠合作的，很多技能不可能同时出现在一个人身上，多数课题组也一般只会关注到一个方向，但如果科学问题的解决需要多角度切入说明，那就拿出诚意去找合作者。环境科学本身就是面向问题出发的，而阐述问题的证据角度越多，结论越靠谱。同时，要不断从基础学科的理论与技术进展中汲取营养，一个学科里聪明人多，那么新思想出的就多，这些思想不仅可以解决这个学科里的问题，也可以解决其他学科的问题。在这一点上，物理、化学与生物的技术进展与计算机科学、统计还有数学的理论思想都值得关注。在那些聪明人比较多的学科里的人也可以搞个跨界，大家共同发展。这里面最明显的就是计算机科学对生物信息学与金融的带动，往往一个学科的进步暗含了其他学科进步的契机。如果你打算做点学术事业，到聪明人最多的学科里去学习，然后回自己的学科里发展。这里面最大的问题就是，一般聪明人多的学科工资要比不那么多的学科高，这时候就得把学术理想当鸡血用了。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;合作&lt;/h2&gt;
&lt;p&gt;有两种做事态度，一种是做所有事都是从自己需求的出发，追求个人的功成名就，科研成果是垫脚石；另一种是从解决问题的需求出发，解决问题是唯一目标，个人名利是副产品。据我观察，两种态度都不影响个人成长与学科进步或退步，但后一种生活态度的人想的少一点，幸福指数要高一点。我个人喜欢面向问题解决问题，当然这个态度会让你不断得罪人你自己还意识不到，不过整体大脑负担小，睡得香。如果面向问题，一作可以不强求、首先发现也可以不要但问题要说明白与说清楚，把好的思想传播出去而不是跟宝贝一样藏着掖着，太阳底下没有新鲜事。这个态度另一个好处就是容易促成合作，如果合作可以成功就比各干各的的社会效益或学科贡献更多。&lt;/p&gt;
&lt;p&gt;很多人都知道囚徒困境里一个比较好的策略就是以牙还牙，但其实这个策略只是可以保证整体收益为零，如果想为正，最好的方法就是双方不断合作。以往的思路都是构建在把自己的课题组搞成巨无霸，目前国内主流就是如此，这样内部合作强于外部合作，容易稳定学术界地位，从这个角度看巨无霸课题组是可取的，我读博的中科院主流基本如此，配合良好的顶层设计可以攻坚克难。但目前来看，如果是一个新课题组长，这样搞一是根本就没那么多资源，二是新人初期很难招到理想的同事。所以此时的优势策略不应该依附大课题组，而应该是跟同龄人合作，在平等的基础上共同成长，面向问题解决问题。不要担心自己的技术被别人学走，别人学走正是说明这个技术有价值，没人学才是大问题。另外，早期技术跟别人合作推广了，你还可以开发新技术嘛，我从未见过有课题组靠一项保密技术可以维持30年的，而对于正常科研人员，30年差不多也该给后辈挪窝了。&lt;/p&gt;
&lt;p&gt;合作是没必要在办公室发生的，很多问题或思路有时候就是差一句话。印象中有公司就通过设计让员工的午餐排队时间控制在3～4分钟左右好让排队时员工能多交流，时间长了员工就出去吃，少了讨论不充分。合作甚至不用物理接触，现在实时通讯工具一大把，随时都可以交流。不过，搞成微信群那样就太花哨，也容易被朋友圈跟红包分散精力，用邮件列表功能又太单一，目前我组内用slack。一方面可以实时交流，另一方面通过区分频道可以针对主题或项目进行讨论协作，此外也可以作为个人项目管理与点对点交流工具。&lt;/p&gt;
&lt;p&gt;我猜的不错的话多数人看到这里也就停了，因为周围可能没有人用，不过万事都有个开头，我已经建立了一个slack主页：yufree.slack.com，欢迎大家给我发邮件slack at yufree.cn拿邀请尝试，不建议留邮箱，原因你懂的。可以当作一个即时交流组队平台的实验品，相互学习，共同进步。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Virtual、世界三与传参</title>
      <link>/cn/2017/04/13/virtual/</link>
      <pubDate>Thu, 13 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/04/13/virtual/</guid>
      <description>&lt;div id=&#34;virtual&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Virtual&lt;/h2&gt;
&lt;p&gt;这个单词究竟怎么翻译曾经困惑我很久，因为实在搞不清究竟它指的是虚拟的还是事实上的，其实两个意思都有。这个词看似精神分裂，但却可以很好的描述当前人的状态，也就是说现实中的虚实界限逐渐在模糊，互联网在这个过程中功不可没。&lt;/p&gt;
&lt;p&gt;首先，大多数文娱活动都是在构建一个Virtual空间。玩一部游戏、读一部小说、看一部电影、听一段音乐甚至欣赏一幅画。你都是在闯入一个异世界，这个世界逻辑矛盾、规矩奇特甚至根本就不可能在现实中遇到，但沉浸其中后，你可能并不会感到什么违和感而更多的是亲切感。在这些空间中可以感到强烈的情感、感同身受的震撼与对背后形而上探求的渴望。但这些并不是喜欢这些活动的真正原因，喜欢Virtual空间其实是因为这个空间比真实空间更舒适。换言之，真实空间的充满了不确定性，而且似乎无始无终，没有太多剧情，没有人去设计也毫不讲道理。&lt;/p&gt;
&lt;p&gt;你可能说，不是啊，世界不是这样啊，你三观有问题太悲观了吧。可以这么说，但抛掉乐观悲观的情感，这个世界里未知的远远多于已知的。如果你突然感染了未知病毒，身体一步步虚弱下去却毫无治疗方法，此时求生的信念毫无事实可以依托该如何面对？&lt;/p&gt;
&lt;p&gt;意识，特别是自我意识，更多是一种进化上副产品。但这个副产品却衍生出了一大堆符号与交流运算体系，甚至构建了文明社会，但回头看看生命体本身，其实就是个碳氢氧等元素的有序组成，且这个有序都有可能是虚幻的，因为自然界不定义有序无序。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;世界三&lt;/h2&gt;
&lt;p&gt;卡尔·波普儿最为人所知的是证伪的思想，但在我看来，他在后期提出的三个世界更合适作为科学研究的指导理论。在这个认识论理论里，世界一指的是物理客体的时空世界，这个世界不受干扰的存在；世界二则是人们的感官或意识世界，绝大多数人通过意识来感知到这个世界，特别是世界一的存在；而世界三则可以看作一个客观的知识世界，这个世界可被感知但不受世界二的干扰，也就是一个共同意识世界。所谓科学研究，大多数时候是站在世界一里运用世界二提炼追求世界三的一种活动，也就是客体-主体-知识体三级跳。而世界三里的科学知识是可证伪的，也就是会存在证据能说明这个知识是错的，如果不可证伪，那么也属于知识，但不是科学研究的领域。这样一来，逻辑跟数学是不算科学，其公理体系是逻辑自洽且无法证伪，但很特殊的是逻辑跟数学却在绝大多数情况下提供了科学研究的工具。另外的一些理论，例如历史唯物主义、精神分析法、行为分析法等虽然逻辑自洽，但无法证伪，也就不在科学讨论的范畴里。这样来看，科学研究是有界限的，界限内可讨论，界限外无法讨论。例如宗教语言等学科，你可以用科学方法去研究，但涉及到形而上的东西谁也说服不了谁的，最经典的解释就是显微镜小妖，据说刚发明显微镜时，宗教人士并不认可细胞结构，于是他们说所有显微镜镜片都有魔鬼附体，看到的是魔鬼的幻象。这个理论从根源上拒斥了讨论的可能，毕竟有个无所不在的魔鬼理论，什么都可以往上推。&lt;/p&gt;
&lt;p&gt;现代社会的一大贡献就是创造了大量的世界三来消耗人类因为劳动力进步而富余的精力，大量的空闲时间是需要多样的娱乐形式来满足的，而娱乐形式不外乎两种：一种让你体验现实存在但不经常发生的事；另一种则直接就是创造一个虚拟空间。值得注意的是，设计这样的虚拟空间也许用不到客体知识世界的严谨性，只需要附加或重构已有规则或规律就可以了，甚至只是单纯描述同样生存规则下另一个人的经历都可以。但我预料，人们会越来越对现实世界感到无聊而滑入新规则世界，特别是在有互联网的今天。越来越多的娱乐作品开始宣传全新的世界观与代入感，好比构建一个新的世界三，而这个世界要比现实世界更刺激但又更安全，这样停留在这里十分舒适。这就好比一个局部最舒适区，也许继续努力会达到一个更舒适的地方，但很多人已然满足。但科学家是不能满足的，因为他们直面的是现实世界里那个规则并不清晰的知识世界并期望自己的努力能让我们对那里的了解更多一点。同样是玩游戏，现实世界的游戏的挑战性其实更多，只是伴随知识积累，容易的基本都被发现了，剩下的都是难题。或者，你可以找出一个新领域。&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;传参&lt;/h2&gt;
&lt;p&gt;人类的娱乐活动是会反过来影响现实生活的，或者说，这两者从来就没有很好的区分过，分不清楚是问题，分得太清楚也是问题。人总是要在多个系统间互相切换的，保持一致性就相当于参数传递，分场景角色扮演就相当于参数独立。很多人精于角色扮演而八面玲珑，但如果没有场景传参，个体就更像是一个完全失去人格的社会动物，只能沉浸在集体里感知自己。但如果传参过多，会让人觉得太过自我，与社会脱节。这个现象出现在社会生活里，也体现在很多细节里，或者说传输规范。&lt;/p&gt;
&lt;p&gt;你打算搜索一个关键词，这个关键词通过拼音或五笔编码输入到屏幕上的搜索栏，确认无误点击搜索，此时数据被统一的规范封包，转换成光信号或电信号进行传输，服务器收到这个信号，用同样的规范解包，然后转化为搜索指令，通过数据库检索返回结果，然后服务器再通过网络传输协议传给你的电脑，经过系统软件与浏览器的翻译，最终你能看到你想要的结果。也就是你动动手指，但为了实现这个目的，其实有无数的传递协议与接口来保驾护航。&lt;/p&gt;
&lt;p&gt;科研过程也是如此，最初你有个想法或发现一个现象，你想告诉其他同行，如果认可就算是做的不错。但事实上交流过程没那么简单，你得确认想法的真实性，这样就需要做实验或调查，通过统计决策或逻辑推理来阐述现象并讨论机理，然后整理成论文，投稿，接受，会议做展示，课堂教授等等。每一步其实都有自己的方法论，你需要保证信息传递过程不被噪音干扰，这并不简单。如果最初目的发生改变，那么这个交流就是无效交流。&lt;/p&gt;
&lt;p&gt;为虚拟现实世界之间的通讯设计构建端口有可能是未来最重要的事，我能想到的问题都出在这个环节。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>搬家</title>
      <link>/cn/2017/04/08/movingagain/</link>
      <pubDate>Sat, 08 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/04/08/movingagain/</guid>
      <description>&lt;p&gt;经过长期跟拖延症的斗争与谢大的&lt;a href=&#34;https://yihui.name/cn/2017/04/url-to-content/&#34;&gt;指引&lt;/a&gt;，我终于在这周把个人网站进行了blogdown一站式处理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为了域名上的小绿锁，我把空间托管所从github pages搬家到了Netlify&lt;/li&gt;
&lt;li&gt;使用Migadu注册了 &lt;a href=&#34;mailto:xx@yufree.cn&#34;&gt;xx@yufree.cn&lt;/a&gt; 域名邮箱，xx当然是42&lt;/li&gt;
&lt;li&gt;DNS解析从万网搬家到了Cloudflare，主要为了域名短一些跟邮箱加密&lt;/li&gt;
&lt;li&gt;中文与英文网站进行了合并处理，中文网站增加笔记入口，英文网站增加代谢组学流程入口，用blogdown管理&lt;/li&gt;
&lt;li&gt;主题自然又是无耻的抄了谢大了，不过我对主题配色与一些细节进行了修改，放在&lt;a href=&#34;https://github.com/yufree/hugo-lithium-theme&#34;&gt;这里&lt;/a&gt;，除非万不得已，应该懒得修改了&lt;/li&gt;
&lt;li&gt;最大的问题就是域名，原来使用了blog跟blogcn，这次用了cn跟en，也就是说你用原来的访问模式看到的gitbub的页面应该不会更新了，rss也会停了&lt;/li&gt;
&lt;li&gt;如果你访问yufree.cn，你会被引导到新网站，但搜索引擎记录的更多的是原来网站的地址，简单说就是你还是可能看到github托管的网页，只是不再更新了&lt;/li&gt;
&lt;li&gt;以后中文博客地址就是https://yufree.cn/cn ，英文则是https://yufree.cn/en&lt;/li&gt;
&lt;li&gt;rss的地址更新如下： - 中文：&lt;a href=&#34;https://yufree.cn/cn/index.xml&#34; class=&#34;uri&#34;&gt;https://yufree.cn/cn/index.xml&lt;/a&gt; - 英文：&lt;a href=&#34;https://yufree.cn/en/index.xml&#34; class=&#34;uri&#34;&gt;https://yufree.cn/en/index.xml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;由此带来的不便深表歉意，但应该不会再搬家了，除非上面的某个服务商倒了。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>